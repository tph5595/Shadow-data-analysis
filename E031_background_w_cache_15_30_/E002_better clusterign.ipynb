{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas matplotlib\n",
    "# Knapsack NP complete could work\n",
    "# or check for candidate DNSers that would be apart of the resource access and with enough resource access and DNS \n",
    "# could probably determine\\\n",
    "\n",
    "\n",
    "# What if determine candicate from DNSers like above but then look at their input to tor (frame size and timing \n",
    "# input and output with TDA to filter down candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f769c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give shadow files old names\n",
    "\n",
    "# import shutil\n",
    "# import os\n",
    "# import sys\n",
    "# import re\n",
    "\n",
    "# dr = \"data/experiment0-0.0001\"\n",
    "\n",
    "# pattern = re.compile(\"^[0-9]*.[0-9]*.[0-9]*.[0-9]*..pcap\")\n",
    "\n",
    "\n",
    "# for root, dirs, files in os.walk(dr):\n",
    "#     for file in files:\n",
    "#         if pattern.match(file):\n",
    "#             spl = root.split(\"/\")\n",
    "#             newname = spl[-1]\n",
    "#             sup = (\"/\").join(spl[:-1])\n",
    "#             shutil.move(root+\"/\"+file, sup+\"/\"+newname+\"-\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get argus flows from PCAPs\n",
    "#!../util/process_data_argus.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b24dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCAP to CSV\n",
    "#!../util/pcap_to_csv.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCAPNG to CSV\n",
    "#!../util/pcapng_to_csv.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d13f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def getFilenames(path):\n",
    "    return [path+f for f in listdir(path) if isfile(join(path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84070c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get argus data\n",
    "arguspath = \"data/argus/csv/\"\n",
    "argusCSVs = getFilenames(arguspath)\n",
    "\n",
    "# Get pcap data\n",
    "pcappath = \"data/csv/\"\n",
    "pcapCSVs = getFilenames(pcappath)\n",
    "data = argusCSVs + pcapCSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e645d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e82b639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame.number</th>\n",
       "      <th>frame.time</th>\n",
       "      <th>ip.src</th>\n",
       "      <th>ip.dst</th>\n",
       "      <th>ip.proto</th>\n",
       "      <th>frame.len</th>\n",
       "      <th>ip.len</th>\n",
       "      <th>ip.flags.df</th>\n",
       "      <th>ip.flags.mf</th>\n",
       "      <th>ip.fragment</th>\n",
       "      <th>...</th>\n",
       "      <th>dtls.handshake.extensions_alpn_str_len</th>\n",
       "      <th>dtls.handshake.extensions_key_share_client_length</th>\n",
       "      <th>http.request</th>\n",
       "      <th>udp.port</th>\n",
       "      <th>frame.time_relative</th>\n",
       "      <th>frame.time_delta</th>\n",
       "      <th>tcp.time_relative</th>\n",
       "      <th>tcp.time_delta</th>\n",
       "      <th>tcp.payload</th>\n",
       "      <th>dns.qry.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dec 31, 1969 19:04:01.000000000 EST</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>100.0.0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Dec 31, 1969 19:04:01.100000000 EST</td>\n",
       "      <td>100.0.0.2</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dec 31, 1969 19:04:01.100000000 EST</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>100.0.0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>557</td>\n",
       "      <td>557</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1603010200010001fc030303ec1b87d2f888b138adcfc6...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Dec 31, 1969 19:04:01.200000000 EST</td>\n",
       "      <td>100.0.0.2</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>6</td>\n",
       "      <td>1211</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>160303009b0200009703031640c97b387b6f6f78fcf04b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Dec 31, 1969 19:04:01.200000000 EST</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>100.0.0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1403030001011703030045157e4a14d6343917c0c1c820...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12617</th>\n",
       "      <td>12618</td>\n",
       "      <td>Dec 31, 1969 21:59:52.321786000 EST</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>185.82.127.11</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10551.321786</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>10549.321786</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12618</th>\n",
       "      <td>12619</td>\n",
       "      <td>Dec 31, 1969 21:59:55.580064000 EST</td>\n",
       "      <td>51.89.148.30</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>6</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10554.580064</td>\n",
       "      <td>3.258278</td>\n",
       "      <td>737.450936</td>\n",
       "      <td>6.001000</td>\n",
       "      <td>17030302135917d9957699453bfbeaa91bffed8ce9c192...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12619</th>\n",
       "      <td>12620</td>\n",
       "      <td>Dec 31, 1969 21:59:55.581064000 EST</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>51.89.148.30</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10554.581064</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>737.451936</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12620</th>\n",
       "      <td>12621</td>\n",
       "      <td>Dec 31, 1969 21:59:59.470064000 EST</td>\n",
       "      <td>185.82.127.11</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>6</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10558.470064</td>\n",
       "      <td>3.889000</td>\n",
       "      <td>10556.470064</td>\n",
       "      <td>7.148278</td>\n",
       "      <td>170303021337123983c572da509d91a3bf07eb0289591b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12621</th>\n",
       "      <td>12622</td>\n",
       "      <td>Dec 31, 1969 21:59:59.470064000 EST</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>185.82.127.11</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10558.470064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10556.470064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12622 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       frame.number                           frame.time         ip.src  \\\n",
       "0                 1  Dec 31, 1969 19:04:01.000000000 EST     102.0.0.85   \n",
       "1                 2  Dec 31, 1969 19:04:01.100000000 EST      100.0.0.2   \n",
       "2                 3  Dec 31, 1969 19:04:01.100000000 EST     102.0.0.85   \n",
       "3                 4  Dec 31, 1969 19:04:01.200000000 EST      100.0.0.2   \n",
       "4                 5  Dec 31, 1969 19:04:01.200000000 EST     102.0.0.85   \n",
       "...             ...                                  ...            ...   \n",
       "12617         12618  Dec 31, 1969 21:59:52.321786000 EST     102.0.0.85   \n",
       "12618         12619  Dec 31, 1969 21:59:55.580064000 EST   51.89.148.30   \n",
       "12619         12620  Dec 31, 1969 21:59:55.581064000 EST     102.0.0.85   \n",
       "12620         12621  Dec 31, 1969 21:59:59.470064000 EST  185.82.127.11   \n",
       "12621         12622  Dec 31, 1969 21:59:59.470064000 EST     102.0.0.85   \n",
       "\n",
       "              ip.dst  ip.proto  frame.len  ip.len  ip.flags.df  ip.flags.mf  \\\n",
       "0          100.0.0.2         6         40      40            1            0   \n",
       "1         102.0.0.85         6         40      40            1            0   \n",
       "2          100.0.0.2         6        557     557            1            0   \n",
       "3         102.0.0.85         6       1211    1211            1            0   \n",
       "4          100.0.0.2         6        120     120            1            0   \n",
       "...              ...       ...        ...     ...          ...          ...   \n",
       "12617  185.82.127.11         6         40      40            1            0   \n",
       "12618     102.0.0.85         6        576     576            1            0   \n",
       "12619   51.89.148.30         6         40      40            1            0   \n",
       "12620     102.0.0.85         6        576     576            1            0   \n",
       "12621  185.82.127.11         6         40      40            1            0   \n",
       "\n",
       "       ip.fragment  ...  dtls.handshake.extensions_alpn_str_len  \\\n",
       "0              NaN  ...                                     NaN   \n",
       "1              NaN  ...                                     NaN   \n",
       "2              NaN  ...                                     NaN   \n",
       "3              NaN  ...                                     NaN   \n",
       "4              NaN  ...                                     NaN   \n",
       "...            ...  ...                                     ...   \n",
       "12617          NaN  ...                                     NaN   \n",
       "12618          NaN  ...                                     NaN   \n",
       "12619          NaN  ...                                     NaN   \n",
       "12620          NaN  ...                                     NaN   \n",
       "12621          NaN  ...                                     NaN   \n",
       "\n",
       "       dtls.handshake.extensions_key_share_client_length  http.request  \\\n",
       "0                                                    NaN           NaN   \n",
       "1                                                    NaN           NaN   \n",
       "2                                                    NaN           NaN   \n",
       "3                                                    NaN           NaN   \n",
       "4                                                    NaN           NaN   \n",
       "...                                                  ...           ...   \n",
       "12617                                                NaN           NaN   \n",
       "12618                                                NaN           NaN   \n",
       "12619                                                NaN           NaN   \n",
       "12620                                                NaN           NaN   \n",
       "12621                                                NaN           NaN   \n",
       "\n",
       "       udp.port  frame.time_relative  frame.time_delta  tcp.time_relative  \\\n",
       "0           NaN             0.000000          0.000000           0.000000   \n",
       "1           NaN             0.100000          0.100000           0.100000   \n",
       "2           NaN             0.100000          0.000000           0.100000   \n",
       "3           NaN             0.200000          0.100000           0.200000   \n",
       "4           NaN             0.200000          0.000000           0.200000   \n",
       "...         ...                  ...               ...                ...   \n",
       "12617       NaN         10551.321786          0.005000       10549.321786   \n",
       "12618       NaN         10554.580064          3.258278         737.450936   \n",
       "12619       NaN         10554.581064          0.001000         737.451936   \n",
       "12620       NaN         10558.470064          3.889000       10556.470064   \n",
       "12621       NaN         10558.470064          0.000000       10556.470064   \n",
       "\n",
       "       tcp.time_delta                                        tcp.payload  \\\n",
       "0            0.000000                                                NaN   \n",
       "1            0.100000                                                NaN   \n",
       "2            0.000000  1603010200010001fc030303ec1b87d2f888b138adcfc6...   \n",
       "3            0.100000  160303009b0200009703031640c97b387b6f6f78fcf04b...   \n",
       "4            0.000000  1403030001011703030045157e4a14d6343917c0c1c820...   \n",
       "...               ...                                                ...   \n",
       "12617        0.005000                                                NaN   \n",
       "12618        6.001000  17030302135917d9957699453bfbeaa91bffed8ce9c192...   \n",
       "12619        0.001000                                                NaN   \n",
       "12620        7.148278  170303021337123983c572da509d91a3bf07eb0289591b...   \n",
       "12621        0.000000                                                NaN   \n",
       "\n",
       "      dns.qry.name  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "...            ...  \n",
       "12617          NaN  \n",
       "12618          NaN  \n",
       "12619          NaN  \n",
       "12620          NaN  \n",
       "12621          NaN  \n",
       "\n",
       "[12622 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv (pcapCSVs[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3cbe7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4fb54b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(argusCSVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ccc7ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrivacyScope:\n",
    "\n",
    "    def __init__(self, filenames, name):\n",
    "        self.name = name\n",
    "        self.filenames = filenames\n",
    "        self.time_format = '%b %d, %Y %X.%f'\n",
    "        self.time_col = 'frame.time'\n",
    "        self.filter_func = lambda df, args: df\n",
    "        self.df = None\n",
    "        self.ip_search_enabled = False\n",
    "        self.cache_search_enabled = False\n",
    "        self.cache_timing = pd.Timedelta(\"300 seconds\")\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"PrivacyScope(\" + self.name + \")\"\n",
    "\n",
    "    def as_df(self, filenames=None):\n",
    "        if self.df is not None:\n",
    "            return self.df\n",
    "        if filenames == None:\n",
    "            filenames = self.filenames\n",
    "        df = pd.DataFrame()\n",
    "        for f in filenames:\n",
    "            ddf = pd.read_csv (f)\n",
    "            df = pd.concat([df, ddf])\n",
    "        self.df = self.format_time_col(df)\n",
    "        return self.df\n",
    "        \n",
    "    def get_ts(self):\n",
    "        return None\n",
    "    \n",
    "    def format_time_col(self, df):\n",
    "        df[self.time_col] = df[self.time_col].apply(lambda x: datetime.strptime(x[:-7], self.time_format))\n",
    "        df.set_index(self.time_col)\n",
    "        return df\n",
    "\n",
    "    def pcap_only(self):\n",
    "        r = re.compile(\".*data/csv.*\")\n",
    "        return list(filter(r.match, self.filenames))\n",
    "    \n",
    "    def pcap_df(self):\n",
    "        return self.as_df(filenames=self.pcap_only())\n",
    "    \n",
    "    def set_filter(self, filter_func):\n",
    "        self.filter_func = filter_func\n",
    "        \n",
    "    def run_filter(self, args):\n",
    "        return self.filter_func(self.as_df(), args)\n",
    "    \n",
    "    def filterByIP(self, ip, run_filter=True, args=None):\n",
    "        df = self.as_df()\n",
    "        if run_filter:\n",
    "            df = self.run_filter(args)\n",
    "        return df[((df['ip.dst'] == ip) | \\\n",
    "                                   (df['ip.src'] == ip))]\n",
    "\n",
    "    def filterByCache(self, ip, cache_data, run_filter=True, args=None):\n",
    "        df = self.as_df()\n",
    "        if run_filter:\n",
    "            df = self.run_filter(args)\n",
    "\n",
    "        df_times = df.index.tolist()\n",
    "        input_times = cache_data.index.tolist()\n",
    "        keepers = [0] * len(df_times)\n",
    "        idx = 0\n",
    "        stop = len(input_times)\n",
    "        for i in range(0, len(df_times)):\n",
    "            if idx >= stop:\n",
    "                break\n",
    "            diff = input_times[idx] - df_times[i]\n",
    "            if diff < 0:\n",
    "                idx += 1\n",
    "            elif diff < self.cache_timing:\n",
    "                keepers[i] = 1  \n",
    "        \n",
    "        return df[keepers]\n",
    "    \n",
    "    def search(self, ip=None, cache_data=None):\n",
    "        matches = []\n",
    "        if self.ip_search_enabled and ip is not None:\n",
    "            matches += [self.filterByIP(ip)]\n",
    "        if self.cache_search_enabled and cache_data is not None:\n",
    "            matches += [self.filterByCache(ip, cache_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "96dd33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Scopes\n",
    "import re\n",
    "\n",
    "# Get all clients and ISP dns scope\n",
    "r = re.compile(\".*isp.csv|.*group[0-9]*user[0-9]*-(?!127\\.0\\.0\\.1)[0-9]*.[0-9]*.[0-9]*.[0-9]*..csv\")\n",
    "ISP_scope = PrivacyScope(list(filter(r.match, data)), \"ISP\")\n",
    "\n",
    "\n",
    "# Access to public resolver scope\n",
    "r = re.compile(\".*isp.csv\")\n",
    "Access_resolver = PrivacyScope(list(filter(r.match, data)), \"Access_resolver\")\n",
    "\n",
    "r = re.compile(\"(.*tld).csv\")\n",
    "tld = PrivacyScope(list(filter(r.match, data)), \"TLD\")\n",
    "\n",
    "r = re.compile(\"(.*root).csv\")\n",
    "root = PrivacyScope(list(filter(r.match, data)), \"root\")\n",
    "\n",
    "r = re.compile(\"(.*sld).csv\")\n",
    "sld = PrivacyScope(list(filter(r.match, data)), \"SLD\")\n",
    "\n",
    "# Access Tor Scope\n",
    "r = re.compile(\".*group[0-9]*user[0-9]*-(?!127\\.0\\.0\\.1)[0-9]*.[0-9]*.[0-9]*.[0-9]*..csv\")\n",
    "Access_tor = PrivacyScope(list(filter(r.match, data)), \"Access_tor\")\n",
    "\n",
    "# Server Public Scope\n",
    "r = re.compile(\".*myMarkovServer0*-(?!127\\.0\\.0\\.1)[0-9]*\\.[0-9]*\\.[0-9]*\\.[0-9]*.csv\")\n",
    "Server_scope = PrivacyScope(list(filter(r.match, data)), \"Server_of_interest\")\n",
    "\n",
    "# tor Exit scope\n",
    "r = re.compile(\".*exit.*\")\n",
    "Tor_exit_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_exit\")\n",
    "\n",
    "# tor Guard scope\n",
    "r = re.compile(\".*guard.*\")\n",
    "Tor_guard_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_guard\")\n",
    "\n",
    "# tor Relay scope\n",
    "r = re.compile(\".*relay.*\")\n",
    "Tor_relay_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_relay\")\n",
    "\n",
    "# tor Middle scope\n",
    "r = re.compile(\".*middle.*\")\n",
    "Tor_middle_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_middle\")\n",
    "\n",
    "# tor 4uthority scope\n",
    "r = re.compile(\".*4uthority.*\")\n",
    "Tor_4uthority_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_4uthority\")\n",
    "\n",
    "# resolver scope\n",
    "r = re.compile(\".*resolver.*\")\n",
    "resolver = PrivacyScope(list(filter(r.match, data)), \"resolver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e568221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def df_to_ts(df):\n",
    "    df['count'] = 1\n",
    "    #  Minute is T\n",
    "    return df.set_index('frame.time').resample('1S').sum(numeric_only=True).rolling(10).sum(numeric_only=True).dropna().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bdada46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_589093/1003319539.py:24: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ddf = pd.read_csv (f)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timedelta('19441 days 13:39:26.634647')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get start time for GNS3\n",
    "GNS3_data = pd.concat([Access_resolver.pcap_df(), sld.pcap_df(), tld.pcap_df(), root.pcap_df()])\n",
    "GNS3_starttime = GNS3_data.head(1)['frame.time'].tolist()[0]\n",
    "Shadow_starttime = datetime.strptime('Dec 31, 1969 19:30:00', '%b %d, %Y %X')\n",
    "Shadow_offset = GNS3_starttime - Shadow_starttime\n",
    "Shadow_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6130e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dns_df = Access_to_auth_zone.pcap_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "311216b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = pd.Timedelta(\"300 seconds\") # cache size but maybe smaller \n",
    "\n",
    "# detect and remove solo quries\n",
    "# these can easily be handled on their own as only 1 device is accessing the network at that moment\n",
    "def detect_solo(df_list):\n",
    "    new_df = df_list[df_list['ip.src'].ne(df_list['ip.src'].shift())]\n",
    "    new_df['diff'] = new_df['frame.time'].diff()\n",
    "    new_df = new_df[new_df['diff'] > window]\n",
    "    solo_ips = new_df['ip.src'].unique()\n",
    "    return solo_ips\n",
    "\n",
    "def handle_solo(solo):\n",
    "    print(\"IPs that must trigger a cache miss: \" + str(solo))\n",
    "    \n",
    "def solo_pipeline(df_list):\n",
    "    fil = df_list[['ip.src', 'frame.time']]\n",
    "    solo = detect_solo(fil)\n",
    "    handle_solo(solo)\n",
    "    return solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0afb005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineScopes(dfs):\n",
    "    if len(dfs) < 1:\n",
    "        return dfs\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def scopesToTS(dfs):\n",
    "    output = []\n",
    "    for df in dfs:\n",
    "        if len(df) < 2:\n",
    "            continue\n",
    "        output += [df_to_ts(df.copy()).set_index('frame.time')]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28054ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup filters for different scopes\n",
    "evil_domain = 'evil.dne'\n",
    "\n",
    "dns_filter = lambda df, ip: df[(df['dns.qry.name'] == evil_domain )\n",
    "                                            | (df['dns.qry.name'] == \"\")]\n",
    "resolver.set_filter(dns_filter)\n",
    "root.set_filter(dns_filter)\n",
    "tld.set_filter(dns_filter)\n",
    "sld.set_filter(dns_filter)\n",
    "\n",
    "\n",
    "resolver.ip_search_enabled = True\n",
    "resolver.cache_search_enabled = False\n",
    "\n",
    "root.ip_search_enabled = True\n",
    "root.cache_search_enabled = True\n",
    "\n",
    "sld.ip_search_enabled = True\n",
    "sld.cache_search_enabled = True\n",
    "\n",
    "tld.ip_search_enabled = True\n",
    "tld.cache_search_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e8ebca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_589093/1875783797.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['diff'] = new_df['frame.time'].diff()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPs that must trigger a cache miss: ['102.0.0.38' '102.0.0.8' '102.0.0.5' '102.0.0.22']\n",
      "scopes: [<__main__.PrivacyScope object at 0x7ff4b99088e0>, <__main__.PrivacyScope object at 0x7ff4bb8ff3a0>, <__main__.PrivacyScope object at 0x7ff4b9c03280>, <__main__.PrivacyScope object at 0x7ff4bb8fdc60>]\n",
      "cache window: 0 days 00:05:00\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\\n           dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Find matches\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[43mscope\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflows_ip\u001b[49m\u001b[43m[\u001b[49m\u001b[43mip\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Update df for ip\u001b[39;00m\n\u001b[1;32m     33\u001b[0m combined_scope \u001b[38;5;241m=\u001b[39m combineScopes([ip_matches, cache_matches])\n",
      "Cell \u001b[0;32mIn[74], line 83\u001b[0m, in \u001b[0;36mPrivacyScope.search\u001b[0;34m(self, ip, cache_data)\u001b[0m\n\u001b[1;32m     81\u001b[0m     matches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilterByIP(ip)]\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_search_enabled \u001b[38;5;129;01mand\u001b[39;00m cache_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     matches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilterByCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_data\u001b[49m\u001b[43m)\u001b[49m]\n",
      "Cell \u001b[0;32mIn[74], line 76\u001b[0m, in \u001b[0;36mPrivacyScope.filterByCache\u001b[0;34m(self, ip, cache_data, run_filter, args)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m diff \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_timing:\n\u001b[1;32m     74\u001b[0m         keepers[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkeepers\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\\n            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\\n           dtype='int64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Cluster DNS\n",
    "## Create ts for each IP\n",
    "resolv_df = resolver.pcap_df()\n",
    "DNS_PROTO = 17.0\n",
    "resolv_df_filtered = resolv_df[resolv_df['ip.proto'] == DNS_PROTO]\n",
    "IPs = resolv_df_filtered['ip.src'].unique()\n",
    "flows_ip = {}\n",
    "flows_ts_ip = {}\n",
    "infra_ip = ['172.20.0.11', '172.20.0.12', '192.168.150.10', '172.20.0.10']\n",
    "first_pass = resolv_df_filtered[((~resolv_df_filtered['ip.src'].isin(infra_ip)))  \\\n",
    "                                         & (resolv_df_filtered['dns.qry.name'] == evil_domain)]\n",
    "solo = solo_pipeline(first_pass)\n",
    "\n",
    "# Add all scope data to IPs found in resolver address space\n",
    "# This should be a valid topo sorted list of the scopes (it will be proccessed in order)\n",
    "scopes = [resolver, sld, tld, root]\n",
    "cache_window = window # see above \n",
    "print(\"scopes: \" + str(scopes))\n",
    "print(\"cache window: \" + str(cache_window))\n",
    "\n",
    "for ip in IPs:\n",
    "    flows_ip[ip] = pd.DataFrame()\n",
    "    flows_ts_ip[ip] = pd.DataFrame()\n",
    "    for scope in scopes:\n",
    "        # Don't add known infra IPs or users that can are solo communicaters\n",
    "        if ip in infra_ip or ip in solo:\n",
    "            continue\n",
    "        \n",
    "        # Find matches\n",
    "        matches = scope.search(ip, flows_ip[ip])\n",
    "        \n",
    "        # Update df for ip\n",
    "        combined_scope = combineScopes([ip_matches, cache_matches])\n",
    "        combined_scope[\"scope_name\"]=scope.name\n",
    "        flows_ip[ip] =combineScopes([flows_ip[ip],combined_scope])\n",
    "        \n",
    "        # update ts for ip\n",
    "        new_ts_matches = combineScopes(scopesToTS([flows_ip[ip]]))\n",
    "        if len(new_ts_matches) == 0:\n",
    "            continue\n",
    "        new_ts_matches[\"scope_name\"]=scope.name\n",
    "        flows_ts_ip[ip] = combineScopes([flows_ts_ip[ip], new_ts_matches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a0b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_ip[ip]['dns.qry.name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63966c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_ts_ip[ip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e47083",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Viz\n",
    "# importing Libraries\n",
    "  \n",
    "# import pandas as pd\n",
    "import pandas as pd\n",
    "  \n",
    "# importing matplotlib module\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "  \n",
    "# %matplotlib inline: only draw static\n",
    "# images in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6360cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "# Visualizing The Open Price of all the stocks\n",
    "  \n",
    "# to set the plot size\n",
    "plt.figure(figsize=(16, 8), dpi=150)\n",
    "  \n",
    "# using plot method to plot open prices.\n",
    "# in plot method we set the label and color of the curve.\n",
    "\n",
    "for f in flows_ts_ip:\n",
    "    flows_ts_ip[f]['count'].plot(label=f)\n",
    "  \n",
    "plt.title('Requests per second')\n",
    "  \n",
    "# adding Label to the x-axis\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Requests (seconds)')\n",
    "  \n",
    "# adding legend to the curve\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688ba61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df, flow):\n",
    "    features = []\n",
    "    # 'first_seen'\n",
    "    features += [float(df['frame.time'].min().timestamp())]\n",
    "    # 'last_seen'\n",
    "    features += [float(df['frame.time'].max().timestamp())]\n",
    "    # 'reqs_per_sec'\n",
    "    features += [flow['count'].mean()]\n",
    "    # 'reqs_per_sec_std'\n",
    "    val = flow['count'].std()\n",
    "    features += [0 if np.isnan(val) else val]\n",
    "    # 'total_req'\n",
    "    features += [len(df)]\n",
    "    # 'reqs_max'\n",
    "    features += [flow['count'].max()]\n",
    "    # 'reqs_min'\n",
    "    features += [flow['count'].min()]\n",
    "    return [features]\n",
    "## Get flow features\n",
    "def all_features(df, flow, bad):\n",
    "    df = df.drop(columns=bad)\n",
    "    df_mean = df.median(numeric_only=True).add_suffix('_mean').to_frame().transpose()\n",
    "    df_min = df.min(numeric_only=True).add_suffix('_min').to_frame().transpose()\n",
    "    df_max = df.max(numeric_only=True).add_suffix('_max').to_frame().transpose()\n",
    "    df_range = df.max(numeric_only=True) - df.min(numeric_only=True)\n",
    "    df_range = df_range.add_suffix('_range').to_frame().transpose()\n",
    "    df_std = df.std(numeric_only=True).add_suffix('_std').to_frame().transpose()\n",
    "    \n",
    "    flow = flow.drop(columns=bad)\n",
    "    ts_mean = flow.mean(numeric_only=True).add_suffix('_mean_ts').to_frame().transpose()\n",
    "    ts_min = flow.min(numeric_only=True).add_suffix('_min_ts').to_frame().transpose()\n",
    "    ts_max = flow.max(numeric_only=True).add_suffix('_max_ts').to_frame().transpose()\n",
    "    ts_range = flow.max(numeric_only=True) - flow.min(numeric_only=True)\n",
    "    ts_range = ts_range.add_suffix('_range_ts').to_frame().transpose()\n",
    "    ts_std = flow.std(numeric_only=True).add_suffix('_std_ts').to_frame().transpose()\n",
    "    \n",
    "    return pd.concat([df_mean, df_min, df_max, df_std, df_range, ts_mean, ts_min, ts_max, ts_std, ts_range], axis=1)\n",
    "cols = ['first_seen','last_seen', 'reqs_per_sec', 'reqs_per_sec_std', 'total_req', 'reqs_max', 'reqs_min']\n",
    "index = []\n",
    "feature_data = []\n",
    "all_f = pd.DataFrame()\n",
    "bad_features = ['udp.port', 'frame.number']\n",
    "for ip in flows_ts_ip:\n",
    "    index += [ip]\n",
    "    feature_data += generate_features(flows_ip[ip], flows_ts_ip[ip])\n",
    "    all_tmp = all_features(flows_ip[ip], flows_ts_ip[ip], bad_features)\n",
    "    all_tmp.index = [ip]\n",
    "    all_f = pd.concat([all_f, all_tmp], axis=0)\n",
    "\n",
    "    # drop col if all na\n",
    "all_f = all_f.dropna(axis=1, how='all')\n",
    "# drop col if all same value\n",
    "nunique = all_f.nunique()\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "all_f = all_f.drop(cols_to_drop, axis=1)\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "df_old = pd.DataFrame(feature_data, columns=cols, index=index)\n",
    "df = all_f\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def ip_to_group(ip):\n",
    "    if ip.split(\".\")[0] != '102':\n",
    "        return -1\n",
    "    return math.floor((int(ip.split(\".\")[-1])-2) / 5)\n",
    "def get_real_label(df):\n",
    "    data = df.index.values\n",
    "    result = np.array([ip_to_group(xi) for xi in data])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09924f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = get_real_label(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a35dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_features = ['frame.time_relative_mean', 'frame.time_relative_std']\n",
    "# df = df[dt_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4a40d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "X = df\n",
    "Y = answers\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=0, max_depth=10)\n",
    "clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67ab163",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz\n",
    "# sudo apt install -y graphviz\n",
    "import graphviz \n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                      feature_names=df.columns,  \n",
    "                      class_names=Y.astype(str),  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best frame.time_relative_mean, frame.time_relative_std\n",
    "# dt_features = ['frame.time_relative_mean', 'frame.time_relative_max', 'frame.time_delta_range']\n",
    "# df = df[dt_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02093d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df=(df-df.min())/(df.max()-df.min())\n",
    "normalized_df = normalized_df.fillna(0)\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from statistics import mean\n",
    "\n",
    "# compute cluster purity\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9662a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_kMeans(df):\n",
    "    df = df.copy(deep=True)\n",
    "    kmeans = KMeans(n_clusters=30, random_state=0, n_init='auto')\n",
    "    df.loc[:,'cluster'] = kmeans.fit_predict(df)# get centroids\n",
    "    df.loc[:,'real_label'] = answers\n",
    "    plt.scatter(df['frame.time_relative_min'], df['frame.time_delta_mean'], c=answers, alpha = 1, s=10)\n",
    "\n",
    "    s = 0\n",
    "    total = 0\n",
    "    for c in df['cluster'].unique():\n",
    "        selection = df[df['cluster'] == c]\n",
    "        p = purity_score(selection['real_label'], selection['cluster'])\n",
    "        total += len(selection)\n",
    "        s += p * len(selection)\n",
    "        print(selection[['cluster', 'real_label']])\n",
    "        print(str(c) + \": \" + str(p))\n",
    "    return s/total\n",
    "purity = my_kMeans(df[['frame.time_delta_mean', 'frame.time_relative_min', 'frame.time_relative_std']])\n",
    "print(\"Average purity: \" + str(purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best features \n",
    "import itertools\n",
    " \n",
    "def findsubsets(s, n):\n",
    "    return list(itertools.combinations(s, n))\n",
    "\n",
    "def iterate_features(df, n):\n",
    "    features = df.columns\n",
    "    best_features = []\n",
    "    best_score = 0.0\n",
    "    for subset in findsubsets(features, n):\n",
    "        subset = list(subset)\n",
    "        score = my_kMeans(df[subset])\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_features = subset\n",
    "            print(best_score)\n",
    "            print(best_features)\n",
    "    return best_features\n",
    "\n",
    "for n in range(1,5):\n",
    "    best_features = iterate_features(df, n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster and viz dns\n",
    "!pip install umap-learn numpy numba\n",
    "# Dimension reduction and clustering libraries\n",
    "#import umap.umap_ as umap\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d14347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized_df=(df-df.min())/(df.max()-df.min())\n",
    "# standard_embedding = umap.UMAP(random_state=42).fit_transform(normalized_df)\n",
    "# plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], c=normalized_df.cluster, s=10, cmap='Spectral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a575ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster who this\n",
    "Server_scope "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881380b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_col_to_str(df, col):\n",
    "    df[col + \"_str\"] = df[col].apply(lambda x: bytearray.fromhex(x).decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a87150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Server resources\n",
    "## Create ts for each resource\n",
    "resource_df = format_time_col(scope_to_df(pcap_only(Server_scope)), 'frame.time')\n",
    "resource_df['frame.time'] = resource_df['frame.time'].apply(lambda x: x+Shadow_offset)\n",
    "resource_df_filtered = resource_df[(resource_df['http.request'].notna())]\n",
    "hex_col_to_str(resource_df_filtered, 'tcp.payload')\n",
    "resource_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953a42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "resource_df_filtered['resource'] = resource_df_filtered['tcp.payload_str'].apply(lambda x: x.split(' ')[1])\n",
    "resource_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98306a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resources = resource_df_filtered['resource'].unique()\n",
    "flows_re = {}\n",
    "flows_ts_re = {}\n",
    "for resource in resources:\n",
    "    flows_re[resource] = resource_df_filtered[(resource_df_filtered['resource'] == resource)]\n",
    "    flows_ts_re[resource] = df_to_ts(flows_re[resource].copy()).set_index('frame.time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ed188",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a886c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generate_features_resource(df, flow):\n",
    "    features = []\n",
    "    # 'first_seen'\n",
    "    #features += [float(df['frame.time'].min().timestamp())]\n",
    "    features += [df['frame.time'].min()]\n",
    "    # 'last_seen'\n",
    "    #features += [float(df['frame.time'].max().timestamp())]\n",
    "    features += [df['frame.time'].max()]\n",
    "    # 'reqs_per_sec'\n",
    "    features += [flow['count'].mean()]\n",
    "    # 'reqs_per_sec_std'\n",
    "    val = flow['count'].std()\n",
    "    features += [0 if np.isnan(val) else val]\n",
    "    # 'total_req'\n",
    "    features += [len(df)]\n",
    "    # 'reqs_max'\n",
    "    features += [flow['count'].max()]\n",
    "    # 'reqs_min'\n",
    "    features += [flow['count'].min()]\n",
    "    return [features]\n",
    "## Get flow features\n",
    "cols = ['first_seen','last_seen', 'reqs_per_sec', 'reqs_per_sec_std', 'total_req', 'reqs_max', 'reqs_min']\n",
    "index = []\n",
    "feature_data = []\n",
    "for ip in flows_re:\n",
    "    index += [ip]\n",
    "    feature_data += generate_features_resource(flows_re[ip], flows_ts_re[ip])\n",
    "\n",
    "  \n",
    "# Create the pandas DataFrame\n",
    "df_resource = pd.DataFrame(feature_data, columns=cols, index=index)\n",
    "df_resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6181298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "# Visualizing The Open Price of all the stocks\n",
    "  \n",
    "# to set the plot size\n",
    "plt.figure(figsize=(16, 8), dpi=150)\n",
    "  \n",
    "# using plot method to plot open prices.\n",
    "# in plot method we set the label and color of the curve.\n",
    "\n",
    "for f in flows_ts_re:\n",
    "    flows_ts_re[f]['count'].plot(label=f)\n",
    "  \n",
    "plt.title('Requests per second')\n",
    "  \n",
    "# adding Label to the x-axis\n",
    "plt.xlabel('Time')\n",
    "  \n",
    "# adding legend to the curve\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b23c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link\n",
    "# Which group has what signal\n",
    "cluser_col_name = 'cluster' # 'real_label'\n",
    "\n",
    "groups = df[cluser_col_name].unique()\n",
    "dtypes = list(flows_ts_ip.values())[0].dtypes.to_dict()\n",
    "cols = list(list(flows_ts_ip.values())[0].columns)\n",
    "sum_ts = {}\n",
    "for group in groups:\n",
    "    sum_ts[group] = pd.DataFrame(columns=cols)\n",
    "    sum_ts[group].astype(dtypes)\n",
    "    #sum_ts[group].set_index('frame.time')\n",
    "for ip in df.index.tolist():\n",
    "    s = flows_ts_ip[ip].add(sum_ts[df.loc[ip][cluser_col_name]], fill_value=0)\n",
    "    sum_ts[df.loc[ip][cluser_col_name]] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8b1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resource_and_groups = sum_ts + flows_ts_re\n",
    "# code\n",
    "# Visualizing The Open Price of all the stocks\n",
    "  \n",
    "# to set the plot size\n",
    "plt.figure(figsize=(16, 8), dpi=150)\n",
    "  \n",
    "# using plot method to plot open prices.\n",
    "# in plot method we set the label and color of the curve.\n",
    "\n",
    "limit = 300\n",
    "\n",
    "for f in flows_ts_re:\n",
    "     flows_ts_re[f]['count'].head(limit).plot(label=f)\n",
    "for f in sum_ts:\n",
    "    #print(min(sum_ts[f].index.values)  - (10 * 1000000000))\n",
    "    if f == -1: # Don't plot resolver\n",
    "        continue\n",
    "    sum_ts[f]['count'].div(4).head(limit).plot(label=f)\n",
    "    \n",
    "  \n",
    "plt.title('Requests per second')\n",
    "  \n",
    "# adding Label to the x-axis\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Packets (scaled)')\n",
    "  \n",
    "# adding legend to the curve\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c7e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mathing groups for resources\n",
    "!pip install pyts\n",
    "\n",
    "from pyts.metrics import dtw, itakura_parallelogram, sakoe_chiba_band\n",
    "from pyts.metrics.dtw import (cost_matrix, accumulated_cost_matrix,\n",
    "                              _return_path, _blurred_path_region)\n",
    "\n",
    "def compare_ts(ts1, ts2):\n",
    "    dtw_classic, path_classic = dtw(ts1, ts2, dist='square',\n",
    "                                method='classic', return_path=True)\n",
    "    return dtw_classic\n",
    "\n",
    "def normalize_ts(ts):\n",
    "    ts=(ts-ts.min())/(ts.max()-ts.min())\n",
    "    return ts.fillna(0)\n",
    "\n",
    "def compare_ts_reshape(ts1, ts2):\n",
    "    ts1_norm = ts1.copy(deep=True)\n",
    "    ts2_norm = ts2.copy(deep=True)\n",
    "    \n",
    "    buffer_room = 30 # in seconds\n",
    "    delay = 120\n",
    "    \n",
    "    # lock to same range with buffer room on each side to account for network (or PPT) delay\n",
    "    start = min(ts1.index.values) + (delay * 1000000000) - (buffer_room * 1000000000)\n",
    "    end = max(ts1.index.values) + (buffer_room * 1000000000)+ (delay * 1000000000)\n",
    "#     print(\"start: \" + str(start))\n",
    "#     print(\"end: \" + str(end))\n",
    "    #print(end - start)\n",
    "    \n",
    "#     ts1_norm = ts1_norm[start:end]\n",
    "    ts2_norm = ts2_norm[start:end]\n",
    "   # print(len(ts2_norm))\n",
    "    \n",
    "    # detect if no overlap\n",
    "    if len(ts1_norm) < 2 or len(ts2_norm) < 2:\n",
    "        return float(\"inf\")\n",
    "    \n",
    "    # Normalize peaks?\n",
    "    ts1_norm = normalize_ts(ts1_norm)\n",
    "    ts2_norm = normalize_ts(ts2_norm)\n",
    "\n",
    "    return compare_ts(ts1_norm, ts2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d90d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = {'/resource0.html': 0, '/resource1.html': 1, '/resource2.html': 2, '/resource3.html': 3, '/resource4.html': 4}\n",
    "num_correct = 0.0\n",
    "for f in flows_ts_re:\n",
    "    print(f)\n",
    "    best_group = -1\n",
    "    best_sim = -1\n",
    "    for c in sum_ts:\n",
    "        if len(sum_ts[c]['count']) < 2:\n",
    "            print(\"\\tGroup \" + str(c) + \" is too short. Skipping\")\n",
    "            continue\n",
    "        sim = compare_ts_reshape(flows_ts_re[f]['count'], sum_ts[c]['count'].div(1))\n",
    "        print(\"\\tGroup \" + str(c) + \"\\t\\tSim:\" + str(sim))\n",
    "        if best_group == -1 or best_sim > sim:\n",
    "            best_group = c\n",
    "            best_sim = sim\n",
    "    print(\"\\n\\tBest match is group \" + str(best_group) + \" with sim \" + str(best_sim))\n",
    "    if answer[f] == best_group:\n",
    "        print('Correct!\\n\\n')\n",
    "        num_correct += 1\n",
    "print(str(num_correct/len(answer) *100) + \"% Correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a8df51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa7c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5760869565217391\n",
    "['frame.time_relative_mean']\n",
    "0.6739130434782609\n",
    "['frame.time_relative_min']\n",
    "\n",
    "0.5760869565217391\n",
    "['frame.time_relative_mean', 'frame.time_delta_mean']\n",
    "0.6630434782608695\n",
    "['frame.time_relative_mean', 'frame.time_relative_min']\n",
    "0.6739130434782609\n",
    "['frame.time_delta_mean', 'frame.time_relative_min']\n",
    "0.6847826086956522\n",
    "['frame.time_relative_min', 'frame.time_delta_max']\n",
    "0.7282608695652174\n",
    "['frame.time_relative_min', 'frame.time_relative_std']\n",
    "\n",
    "0.6630434782608695\n",
    "['frame.time_relative_mean', 'frame.time_delta_mean', 'frame.time_relative_min']\n",
    "0.6956521739130435\n",
    "['frame.time_relative_mean', 'frame.time_relative_min', 'frame.time_relative_std']\n",
    "0.717391304347826\n",
    "['frame.time_relative_mean', 'frame.time_relative_min', 'frame.time_delta_mean_ts']\n",
    "0.7282608695652174\n",
    "['frame.time_delta_mean', 'frame.time_relative_min', 'frame.time_relative_std']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
