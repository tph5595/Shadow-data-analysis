{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018229cb-b8e1-49e7-a602-2b6603d33676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import importlib\n",
    "import yaml\n",
    "import sys\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import heapq\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "# Local Imports\n",
    "from TDA import TDA_Parameters, ts_to_tda\n",
    "from CrossCorrelation import cross_cor\n",
    "from Metrics import recall_at_k, heap_to_ordered_list, get_value_position\n",
    "from Preprocess import preprocess\n",
    "from CastCol import cast_columns\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Config\n",
    "# ==============================================================================\n",
    "if len(sys.argv) < 2:\n",
    "    print(\"Usage: python {} <config.yaml>\".format(sys.argv[0]))\n",
    "    sys.exit(1)\n",
    "\n",
    "config_file = sys.argv[1]\n",
    "with open(config_file, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "# ==============================================================================\n",
    "# END Config\n",
    "# ==============================================================================\n",
    "\n",
    "window = pd.Timedelta(config['window'])\n",
    "num_cpus = config['num_cpus']\n",
    "\n",
    "module = importlib.import_module('ScopeFilters')\n",
    "for scope in config['scope_config']:\n",
    "    scope[2] = getattr(module, scope[2])\n",
    "\n",
    "tda_config = TDA_Parameters(config['dim'],\n",
    "                            config['tda_window'],\n",
    "                            config['skip'],\n",
    "                            config['k'],\n",
    "                            float(config['thresh']))\n",
    "\n",
    "\n",
    "src, dst = preprocess(config['pcappath'],\n",
    "                      config['logpath'],\n",
    "                      config['scope_config'],\n",
    "                      config['server_logs'],\n",
    "                      config['infra_ip'],\n",
    "                      window,\n",
    "                      config['evil_domain'],\n",
    "                      config['bad_features'],\n",
    "                      debug=config['DEBUG'])\n",
    "\n",
    "p_filename = config['experiment_name'] + \"_ts.pkl\"\n",
    "with open(p_filename, 'wb') as file:\n",
    "    pickle.dump(src, file)\n",
    "    pickle.dump(dst, file)\n",
    "\n",
    "with open(p_filename, 'rb') as file:\n",
    "    flows_ts_ip_total = pickle.load(file)\n",
    "    client_chat_logs = pickle.load(file)\n",
    "\n",
    "for ip in flows_ts_ip_total:\n",
    "    cast_columns(flows_ts_ip_total[ip])\n",
    "\n",
    "for user in client_chat_logs:\n",
    "    cast_columns(client_chat_logs[user])\n",
    "\n",
    "\n",
    "# def ip_to_group(ip):\n",
    "#     if isinstance(ip, float) or ip.split(\".\")[0] != '102':\n",
    "#         return -1\n",
    "#     return math.floor((int(ip.split(\".\")[-1])-2) / 5)\n",
    "\n",
    "\n",
    "# def get_real_label(dic):\n",
    "#     data = dic.keys()\n",
    "#     result = np.array([ip_to_group(xi) for xi in data])\n",
    "#     return result\n",
    "\n",
    "\n",
    "# answers = get_real_label(flows_ts_ip_total)\n",
    "\n",
    "\n",
    "def my_dtw(ts1, ts2):\n",
    "    distance, path = fastdtw(ts1, ts2)\n",
    "    return distance\n",
    "\n",
    "\n",
    "def my_pl_ts(ts1, ts2, ip1, ip2):\n",
    "    return my_dtw(ts1, ts2)\n",
    "\n",
    "\n",
    "def my_dist(ts1, ts2, ip1=\"\", ip2=\"\"):\n",
    "    return my_pl_ts(ts1, ts2, ip1, ip2)\n",
    "\n",
    "\n",
    "def ip_to_user(ip, group_size=5, starting=5):\n",
    "    isp = int(int(ip.split(\".\")[-2]))\n",
    "    node_number = int(ip.split(\".\")[-1]) - starting - isp\n",
    "    user = node_number % group_size\n",
    "    group = math.floor(node_number / group_size)\n",
    "    return '/tordata/config/group_' + str(group) + \"_user_\" + str(user)\n",
    "\n",
    "\n",
    "def compare_ts(ts1, ts2, debug=False):\n",
    "    # dtw_classic, path_classic = dtw(ts1, ts2, dist='square',\n",
    "    #                             method='classic', return_path=True)\n",
    "    # return dtw_classic\n",
    "    # print(ts1)\n",
    "    # print(ts2)\n",
    "    # dist, lag = cross_cor(pd.Series(ts1), pd.Series(ts2))\n",
    "    dist, lag = cross_cor(ts1, ts2, debug=debug)\n",
    "    # assert dist >= -1 and dist <= 1\n",
    "    dist = dist * -1  # flip for use as distance metric\n",
    "    # assert dist >= -1 and dist <= 1\n",
    "    return dist, lag\n",
    "\n",
    "\n",
    "def normalize_ts(ts):\n",
    "    ts = (ts-ts.min())/(ts.max()-ts.min())\n",
    "    return ts.fillna(0)\n",
    "\n",
    "\n",
    "def compare_ts_reshape(ts1, ts2, debug=False):\n",
    "    # buffer_room = 120  # in seconds\n",
    "    range = min(ts2.index.values), max(ts2.index.values)\n",
    "    ts1 = ts1.loc[(ts1.index >= range[0]) & (ts1.index <= range[1])]\n",
    "    # ts1 = ts1[(ts1['frame.time'] >= int(range[0])) &\n",
    "    #           (ts1['frame.time'] <= int(range[1]))]\n",
    "    # print(ts1)\n",
    "    # ts1 = ts1.loc[:, 'tda_pl']\n",
    "    ts1 = ts1.values[:, 0]\n",
    "\n",
    "    ts1_norm = np.array(ts1)\n",
    "    ts2_norm = np.array(ts2)\n",
    "\n",
    "    # delay = 0\n",
    "\n",
    "    # ts1_norm.index = ts1_norm.index + pd.DateOffset(seconds=delay)\n",
    "\n",
    "    # lock to same range with buffer room\n",
    "    # on each side to account for network (or PPT) delay\n",
    "\n",
    "    # detect if no overlap\n",
    "    if len(ts1_norm) < 2 or len(ts2_norm) < 2:\n",
    "        return float(\"inf\"), 0\n",
    "\n",
    "    # Normalize peaks?\n",
    "    # ts1_norm = normalize_ts(ts1_norm)\n",
    "    # ts2_norm = normalize_ts(ts2_norm)\n",
    "\n",
    "    # plot_ts(ts1_norm, ts2_norm)\n",
    "    # exit(1)\n",
    "\n",
    "    # else:\n",
    "    #     ts1_norm = ts1_norm.tolist()\n",
    "    #     ts2_norm = ts2_norm.tolist()\n",
    "\n",
    "    score, lag = compare_ts(ts1_norm, ts2_norm, debug=debug)\n",
    "\n",
    "    return score, lag\n",
    "\n",
    "\n",
    "def evaluate(src_raw, dst_raw, src_features, dst_feaures, display=False, params=TDA_Parameters(0, 3, 1, 1, 1)):\n",
    "    src = {}\n",
    "    dst = {}\n",
    "    for ip in src_raw:\n",
    "        try:\n",
    "            data = src_raw[ip][src_features].copy(deep=True)\n",
    "        except Exception:\n",
    "            data = pd.DataFrame(0, index=src_raw[ip].index, columns=src_features)\n",
    "        if config['tda']:\n",
    "            src[ip] = ts_to_tda(data)\n",
    "        else:\n",
    "            src[ip] = data\n",
    "    for user in dst_raw:\n",
    "        try:\n",
    "            data = dst_raw[user][dst_feaures].copy(deep=True)\n",
    "        except Exception:\n",
    "            data = pd.DataFrame(0, index=dst_raw[user].index, columns=dst_feaures)\n",
    "        if config['tda']:\n",
    "            dst[user] = ts_to_tda(data)\n",
    "        else:\n",
    "            dst[user] = data\n",
    "\n",
    "    correct = 0.0\n",
    "    rank_list = []\n",
    "    score_list = []\n",
    "    recall_2 = 0\n",
    "    recall_4 = 0\n",
    "    recall_8 = 0\n",
    "    rank = 0\n",
    "    for user in dst:\n",
    "        best_score = 0\n",
    "        best_user = 0\n",
    "        heap = []\n",
    "        counter = 0\n",
    "        r2 = False\n",
    "        r4 = False\n",
    "        r8 = False\n",
    "        for ip in src:\n",
    "            counter += 1\n",
    "            score, _ = compare_ts_reshape(src[ip], dst[user])\n",
    "            if not math.isnan(score) and not math.isinf(score):\n",
    "                heapq.heappush(heap, (score, counter, ip_to_user(ip)))\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_user = ip_to_user(ip)\n",
    "        if user == best_user:\n",
    "            correct += 1\n",
    "        # print(user)\n",
    "        if recall_at_k(heap.copy(), 2, user):\n",
    "            recall_2 += 1\n",
    "            r2 = True\n",
    "        if recall_at_k(heap.copy(), 4, user):\n",
    "            recall_4 += 1\n",
    "            r4 = True\n",
    "        if recall_at_k(heap.copy(), 8, user):\n",
    "            recall_8 += 1\n",
    "            r8 = True\n",
    "        if (r2 and (not r4 or not r8)) or (r4 and not r8):\n",
    "            print(\"r2: \" + str(r2))\n",
    "            print(\"r4: \" + str(r4))\n",
    "            print(\"r8: \" + str(r8))\n",
    "            raise Exception(\"Bad recall\")\n",
    "        rank += get_value_position(heap, user)\n",
    "        rank_list += [(get_value_position(heap, user), user)]\n",
    "        score_list += [(heap_to_ordered_list(heap), user)]\n",
    "    accuracy = correct / len(src)\n",
    "    recall_2 = recall_2 / len(src)\n",
    "    recall_4 = recall_4 / len(src)\n",
    "    recall_8 = recall_8 / len(src)\n",
    "    rank = rank / len(src)\n",
    "    return accuracy, recall_2, recall_4, recall_8, rank, rank_list, score_list\n",
    "\n",
    "\n",
    "def findsubsets(s, n):\n",
    "    return list(itertools.combinations(s, n))\n",
    "\n",
    "\n",
    "def evaluate_subset(src_df, dst_df, src_features, dst_feaures, tda_config=None):\n",
    "    score = evaluate(src_df, dst_df, list(src_features), list(dst_feaures), params=tda_config)\n",
    "    return score, src_features\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = []\n",
    "    for src in df:\n",
    "        features += df[src].columns.tolist()\n",
    "    return list(set(features))\n",
    "\n",
    "\n",
    "def iterate_features(src_df, dst_df, n, dst_features, tda_config, filename):\n",
    "    features = get_features(src_df)\n",
    "    subsets = findsubsets(features, n)\n",
    "    results = []\n",
    "    print(\"Using \" + str(num_cpus) + \" cpus for \" + str(len(subsets)) + \" subsets\")\n",
    "    with mp.Pool(processes=num_cpus) as pool:\n",
    "        results = []\n",
    "        for subset in subsets:\n",
    "            results.append(pool.apply_async(evaluate_subset, args=(src_df, dst_df, subset, dst_features, tda_config)))\n",
    "        with open(filename, 'a+') as f:\n",
    "            for result in tqdm(results, total=len(subsets)):\n",
    "                score, subset = result.get()\n",
    "                out = str(score) + \"\\t\" + str(subset) + \"\\n\"\n",
    "                f.write(out)\n",
    "\n",
    "\n",
    "src_df = flows_ts_ip_total\n",
    "dst_df = client_chat_logs\n",
    "\n",
    "# dst_features = ['count']\n",
    "# src_features = ['count']\n",
    "# n = 1\n",
    "# data = evaluate_subset(src_df, dst_df, src_features, dst_features)[-2][-1]\n",
    "# with open(output_file, 'w') as f:\n",
    "#     for i in data:\n",
    "#         out = str(i[-1]) + \", \" + str(i[0]) + \"\\n\"\n",
    "#         f.write(out)\n",
    "\n",
    "for output_size in range(1, len(dst_df)+1):\n",
    "    for n in range(1, 3):\n",
    "        for features in findsubsets(get_features(dst_df), output_size):\n",
    "            print(\"Evaluating \" + str(n) + \" features from \" + str(output_size) + \" output features\")\n",
    "            best_features = iterate_features(src_df, dst_df, n, features, tda_config,\n",
    "                                             config['experiment_name'] + str(n) +\n",
    "                                             \"_outputFeatures_\" + str(features) +\n",
    "                                             \"_\" + str(datetime.now()) +\n",
    "                                             \".output\")\n",
    "import itertools\n",
    "import importlib\n",
    "import yaml\n",
    "import sys\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "import heapq\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "# Local Imports\n",
    "from TDA import TDA_Parameters, ts_to_tda\n",
    "from CrossCorrelation import cross_cor\n",
    "from Metrics import recall_at_k, heap_to_ordered_list, get_value_position\n",
    "from Preprocess import preprocess\n",
    "from CastCol import cast_columns\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Config\n",
    "# ==============================================================================\n",
    "if len(sys.argv) < 2:\n",
    "    print(\"Usage: python {} <config.yaml>\".format(sys.argv[0]))\n",
    "    sys.exit(1)\n",
    "\n",
    "config_file = sys.argv[1]\n",
    "with open(config_file, 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "# ==============================================================================\n",
    "# END Config\n",
    "# ==============================================================================\n",
    "\n",
    "window = pd.Timedelta(config['window'])\n",
    "num_cpus = config['num_cpus']\n",
    "\n",
    "module = importlib.import_module('ScopeFilters')\n",
    "for scope in config['scope_config']:\n",
    "    scope[2] = getattr(module, scope[2])\n",
    "\n",
    "tda_config = TDA_Parameters(config['dim'],\n",
    "                            config['tda_window'],\n",
    "                            config['skip'],\n",
    "                            config['k'],\n",
    "                            float(config['thresh']))\n",
    "\n",
    "\n",
    "src, dst = preprocess(config['pcappath'],\n",
    "                      config['logpath'],\n",
    "                      config['scope_config'],\n",
    "                      config['server_logs'],\n",
    "                      config['infra_ip'],\n",
    "                      window,\n",
    "                      config['evil_domain'],\n",
    "                      config['bad_features'],\n",
    "                      debug=config['DEBUG'])\n",
    "\n",
    "p_filename = config['experiment_name'] + \"_ts.pkl\"\n",
    "with open(p_filename, 'wb') as file:\n",
    "    pickle.dump(src, file)\n",
    "    pickle.dump(dst, file)\n",
    "\n",
    "with open(p_filename, 'rb') as file:\n",
    "    flows_ts_ip_total = pickle.load(file)\n",
    "    client_chat_logs = pickle.load(file)\n",
    "\n",
    "for ip in flows_ts_ip_total:\n",
    "    cast_columns(flows_ts_ip_total[ip])\n",
    "\n",
    "for user in client_chat_logs:\n",
    "    cast_columns(client_chat_logs[user])\n",
    "\n",
    "\n",
    "# def ip_to_group(ip):\n",
    "#     if isinstance(ip, float) or ip.split(\".\")[0] != '102':\n",
    "#         return -1\n",
    "#     return math.floor((int(ip.split(\".\")[-1])-2) / 5)\n",
    "\n",
    "\n",
    "# def get_real_label(dic):\n",
    "#     data = dic.keys()\n",
    "#     result = np.array([ip_to_group(xi) for xi in data])\n",
    "#     return result\n",
    "\n",
    "\n",
    "# answers = get_real_label(flows_ts_ip_total)\n",
    "\n",
    "\n",
    "def my_dtw(ts1, ts2):\n",
    "    distance, path = fastdtw(ts1, ts2)\n",
    "    return distance\n",
    "\n",
    "\n",
    "def my_pl_ts(ts1, ts2, ip1, ip2):\n",
    "    return my_dtw(ts1, ts2)\n",
    "\n",
    "\n",
    "def my_dist(ts1, ts2, ip1=\"\", ip2=\"\"):\n",
    "    return my_pl_ts(ts1, ts2, ip1, ip2)\n",
    "\n",
    "\n",
    "def ip_to_user(ip, group_size=5, starting=5):\n",
    "    isp = int(int(ip.split(\".\")[-2]))\n",
    "    node_number = int(ip.split(\".\")[-1]) - starting - isp\n",
    "    user = node_number % group_size\n",
    "    group = math.floor(node_number / group_size)\n",
    "    return '/tordata/config/group_' + str(group) + \"_user_\" + str(user)\n",
    "\n",
    "\n",
    "def compare_ts(ts1, ts2, debug=False):\n",
    "    # dtw_classic, path_classic = dtw(ts1, ts2, dist='square',\n",
    "    #                             method='classic', return_path=True)\n",
    "    # return dtw_classic\n",
    "    # print(ts1)\n",
    "    # print(ts2)\n",
    "    # dist, lag = cross_cor(pd.Series(ts1), pd.Series(ts2))\n",
    "    dist, lag = cross_cor(ts1, ts2, debug=debug)\n",
    "    # assert dist >= -1 and dist <= 1\n",
    "    dist = dist * -1  # flip for use as distance metric\n",
    "    # assert dist >= -1 and dist <= 1\n",
    "    return dist, lag\n",
    "\n",
    "\n",
    "def normalize_ts(ts):\n",
    "    ts = (ts-ts.min())/(ts.max()-ts.min())\n",
    "    return ts.fillna(0)\n",
    "\n",
    "\n",
    "def compare_ts_reshape(ts1, ts2, debug=False):\n",
    "    # buffer_room = 120  # in seconds\n",
    "    range = min(ts2.index.values), max(ts2.index.values)\n",
    "    ts1 = ts1.loc[(ts1.index >= range[0]) & (ts1.index <= range[1])]\n",
    "    # ts1 = ts1[(ts1['frame.time'] >= int(range[0])) &\n",
    "    #           (ts1['frame.time'] <= int(range[1]))]\n",
    "    # print(ts1)\n",
    "    # ts1 = ts1.loc[:, 'tda_pl']\n",
    "    ts1 = ts1.values[:, 0]\n",
    "\n",
    "    ts1_norm = np.array(ts1)\n",
    "    ts2_norm = np.array(ts2)\n",
    "\n",
    "    # delay = 0\n",
    "\n",
    "    # ts1_norm.index = ts1_norm.index + pd.DateOffset(seconds=delay)\n",
    "\n",
    "    # lock to same range with buffer room\n",
    "    # on each side to account for network (or PPT) delay\n",
    "\n",
    "    # detect if no overlap\n",
    "    if len(ts1_norm) < 2 or len(ts2_norm) < 2:\n",
    "        return float(\"inf\"), 0\n",
    "\n",
    "    # Normalize peaks?\n",
    "    # ts1_norm = normalize_ts(ts1_norm)\n",
    "    # ts2_norm = normalize_ts(ts2_norm)\n",
    "\n",
    "    # plot_ts(ts1_norm, ts2_norm)\n",
    "    # exit(1)\n",
    "\n",
    "    # else:\n",
    "    #     ts1_norm = ts1_norm.tolist()\n",
    "    #     ts2_norm = ts2_norm.tolist()\n",
    "\n",
    "    score, lag = compare_ts(ts1_norm, ts2_norm, debug=debug)\n",
    "\n",
    "    return score, lag\n",
    "\n",
    "\n",
    "def evaluate(src_raw, dst_raw, src_features, dst_feaures, display=False, params=TDA_Parameters(0, 3, 1, 1, 1)):\n",
    "    src = {}\n",
    "    dst = {}\n",
    "    for ip in src_raw:\n",
    "        try:\n",
    "            data = src_raw[ip][src_features].copy(deep=True)\n",
    "        except Exception:\n",
    "            data = pd.DataFrame(0, index=src_raw[ip].index, columns=src_features)\n",
    "        if config['tda']:\n",
    "            src[ip] = ts_to_tda(data)\n",
    "        else:\n",
    "            src[ip] = data\n",
    "    for user in dst_raw:\n",
    "        try:\n",
    "            data = dst_raw[user][dst_feaures].copy(deep=True)\n",
    "        except Exception:\n",
    "            data = pd.DataFrame(0, index=dst_raw[user].index, columns=dst_feaures)\n",
    "        if config['tda']:\n",
    "            dst[user] = ts_to_tda(data)\n",
    "        else:\n",
    "            dst[user] = data\n",
    "\n",
    "    correct = 0.0\n",
    "    rank_list = []\n",
    "    score_list = []\n",
    "    recall_2 = 0\n",
    "    recall_4 = 0\n",
    "    recall_8 = 0\n",
    "    rank = 0\n",
    "    for user in dst:\n",
    "        best_score = 0\n",
    "        best_user = 0\n",
    "        heap = []\n",
    "        counter = 0\n",
    "        r2 = False\n",
    "        r4 = False\n",
    "        r8 = False\n",
    "        for ip in src:\n",
    "            counter += 1\n",
    "            score, _ = compare_ts_reshape(src[ip], dst[user])\n",
    "            if not math.isnan(score) and not math.isinf(score):\n",
    "                heapq.heappush(heap, (score, counter, ip_to_user(ip)))\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_user = ip_to_user(ip)\n",
    "        if user == best_user:\n",
    "            correct += 1\n",
    "        # print(user)\n",
    "        if recall_at_k(heap.copy(), 2, user):\n",
    "            recall_2 += 1\n",
    "            r2 = True\n",
    "        if recall_at_k(heap.copy(), 4, user):\n",
    "            recall_4 += 1\n",
    "            r4 = True\n",
    "        if recall_at_k(heap.copy(), 8, user):\n",
    "            recall_8 += 1\n",
    "            r8 = True\n",
    "        if (r2 and (not r4 or not r8)) or (r4 and not r8):\n",
    "            print(\"r2: \" + str(r2))\n",
    "            print(\"r4: \" + str(r4))\n",
    "            print(\"r8: \" + str(r8))\n",
    "            raise Exception(\"Bad recall\")\n",
    "        rank += get_value_position(heap, user)\n",
    "        rank_list += [(get_value_position(heap, user), user)]\n",
    "        score_list += [(heap_to_ordered_list(heap), user)]\n",
    "    accuracy = correct / len(src)\n",
    "    recall_2 = recall_2 / len(src)\n",
    "    recall_4 = recall_4 / len(src)\n",
    "    recall_8 = recall_8 / len(src)\n",
    "    rank = rank / len(src)\n",
    "    return accuracy, recall_2, recall_4, recall_8, rank, rank_list, score_list\n",
    "\n",
    "\n",
    "def findsubsets(s, n):\n",
    "    return list(itertools.combinations(s, n))\n",
    "\n",
    "\n",
    "def evaluate_subset(src_df, dst_df, src_features, dst_feaures, tda_config=None):\n",
    "    score = evaluate(src_df, dst_df, list(src_features), list(dst_feaures), params=tda_config)\n",
    "    return score, src_features\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = []\n",
    "    for src in df:\n",
    "        features += df[src].columns.tolist()\n",
    "    return list(set(features))\n",
    "\n",
    "\n",
    "def iterate_features(src_df, dst_df, n, dst_features, tda_config, filename):\n",
    "    features = get_features(src_df)\n",
    "    subsets = findsubsets(features, n)\n",
    "    results = []\n",
    "    print(\"Using \" + str(num_cpus) + \" cpus for \" + str(len(subsets)) + \" subsets\")\n",
    "    with mp.Pool(processes=num_cpus) as pool:\n",
    "        results = []\n",
    "        for subset in subsets:\n",
    "            results.append(pool.apply_async(evaluate_subset, args=(src_df, dst_df, subset, dst_features, tda_config)))\n",
    "        with open(filename, 'a+') as f:\n",
    "            for result in tqdm(results, total=len(subsets)):\n",
    "                score, subset = result.get()\n",
    "                out = str(score) + \"\\t\" + str(subset) + \"\\n\"\n",
    "                f.write(out)\n",
    "\n",
    "\n",
    "src_df = flows_ts_ip_total\n",
    "dst_df = client_chat_logs\n",
    "\n",
    "# dst_features = ['count']\n",
    "# src_features = ['count']\n",
    "# n = 1\n",
    "# data = evaluate_subset(src_df, dst_df, src_features, dst_features)[-2][-1]\n",
    "# with open(output_file, 'w') as f:\n",
    "#     for i in data:\n",
    "#         out = str(i[-1]) + \", \" + str(i[0]) + \"\\n\"\n",
    "#         f.write(out)\n",
    "\n",
    "for output_size in range(1, len(dst_df)+1):\n",
    "    for n in range(1, 3):\n",
    "        for features in findsubsets(get_features(dst_df), output_size):\n",
    "            print(\"Evaluating \" + str(n) + \" features from \" + str(output_size) + \" output features\")\n",
    "            best_features = iterate_features(src_df, dst_df, n, features, tda_config,\n",
    "                                             config['experiment_name'] + str(n) +\n",
    "                                             \"_outputFeatures_\" + str(features) +\n",
    "                                             \"_\" + str(datetime.now()) +\n",
    "                                             \".output\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
