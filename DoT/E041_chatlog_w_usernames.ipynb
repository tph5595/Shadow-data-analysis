{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8136c63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scopes created\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import metrics\n",
    "# from statistics import mean\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import (adjusted_rand_score,\n",
    "                             normalized_mutual_info_score,\n",
    "                             fowlkes_mallows_score,\n",
    "                             homogeneity_completeness_v_measure)\n",
    "from ripser import ripser\n",
    "# from sklearn import preprocessing\n",
    "from fastdtw import fastdtw\n",
    "import fast_pl_py\n",
    "# from scipy.spatial.distance import pdist\n",
    "import statsmodels.api as sm\n",
    "# from pyts.metrics import dtw, itakura_parallelogram, sakoe_chiba_band\n",
    "# rom pyts.metrics.dtw import (cost_matrix, accumulated_cost_matrix,\n",
    "#                             _return_path, _blurred_path_region)\n",
    "\n",
    "\n",
    "def getFilenames(path):\n",
    "    return [path+f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "\n",
    "# Get argus data\n",
    "# arguspath = \"data/argus/csv/\"\n",
    "# argusCSVs = getFilenames(arguspath)\n",
    "\n",
    "# Get pcap data\n",
    "pcappath = \"data/csv/\"\n",
    "pcapCSVs = getFilenames(pcappath)\n",
    "\n",
    "# Get server logs\n",
    "logpath = \"data/experiment0-0.01/shadow.data/hosts/mymarkovservice0/\"\n",
    "logs = getFilenames(logpath)\n",
    "\n",
    "# Combine all locations\n",
    "# data = argusCSVs + pcapCSVs + logs\n",
    "data = pcapCSVs + logs\n",
    "\n",
    "df = pd.read_csv(pcapCSVs[0])\n",
    "\n",
    "\n",
    "class PrivacyScope:\n",
    "\n",
    "    def __init__(self, filenames, name):\n",
    "        self.name = name\n",
    "        self.filenames = filenames\n",
    "        self.time_format = '%b %d, %Y %X.%f'\n",
    "        self.time_cut_tail = -7\n",
    "        self.time_col = 'frame.time'\n",
    "        self.filter_func = lambda df, args: df\n",
    "        self.df = None\n",
    "        self.ip_search_enabled = False\n",
    "        self.cache_search_enabled = False\n",
    "        self.cache_timing = pd.Timedelta(\"300 seconds\")\n",
    "        self.generated = False\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "    def __repr(self):\n",
    "        return str(self)\n",
    "\n",
    "    def start_time(self):\n",
    "        return self.as_df().index.min()\n",
    "\n",
    "    def set_offset(self, timeoffset):\n",
    "        self.timeoffset = timeoffset\n",
    "        self.as_df()\n",
    "        self.df.index += timeoffset\n",
    "    \n",
    "    def set_index(self, col_name):\n",
    "        df = self.as_df()\n",
    "        df.set_index(col_name, inplace=True)\n",
    "        self.df = df\n",
    "        return df\n",
    "\n",
    "    def process_log(self, fn, sep='\\t', cols=[\"time\", \"format\", \"data\"]):\n",
    "        df = pd.read_csv(fn, sep=sep, names=cols)\n",
    "        m = pd.json_normalize(df[\"data\"].apply(json.loads))\n",
    "        df.drop([\"data\"], axis=1, inplace=True)\n",
    "        df = pd.concat([df, m], axis=1, sort=False)\n",
    "        return df\n",
    "\n",
    "    def as_df(self, filenames=None):\n",
    "        if self.df is not None:\n",
    "            return self.df\n",
    "        if filenames is None:\n",
    "            filenames = self.filenames\n",
    "        df = pd.DataFrame()\n",
    "        for f in filenames:\n",
    "            if f.endswith(\".csv\"):\n",
    "                ddf = pd.read_csv(f)\n",
    "            elif f.endswith(\"stdout\"):\n",
    "                ddf = self.process_log(f)\n",
    "            df = pd.concat([df, ddf])\n",
    "        self.df = df\n",
    "        self.format_time_col()\n",
    "        return self.df\n",
    "\n",
    "    def get_ts(self):\n",
    "        return None\n",
    "\n",
    "    def format_time_col(self):\n",
    "        if self.time_format == 'epoch':\n",
    "            self.df[self.time_col] = \\\n",
    "                    self.df[self.time_col].apply(\n",
    "                            lambda x: datetime.fromtimestamp(float(x)))\n",
    "        else:\n",
    "            self.df[self.time_col] = \\\n",
    "                    self.df[self.time_col].apply(\n",
    "                            lambda x: datetime.strptime(\n",
    "                                x[:self.time_cut_tail], self.time_format))\n",
    "        return self.df\n",
    "\n",
    "    def pcap_only(self):\n",
    "        r = re.compile(\".*data/csv.*\")\n",
    "        return list(filter(r.match, self.filenames))\n",
    "\n",
    "    def pcap_df(self):\n",
    "        assert self.df is None\n",
    "        return self.as_df(filenames=self.pcap_only())\n",
    "\n",
    "    def set_filter(self, filter_func):\n",
    "        self.filter_func = filter_func\n",
    "\n",
    "    def run_filter(self, args):\n",
    "        return self.filter_func(self.as_df(), args)\n",
    "\n",
    "    def filterByIP(self, ip, run_filter=True, args=None):\n",
    "        df = self.as_df()\n",
    "        if run_filter:\n",
    "            df = self.run_filter(args)\n",
    "        return df[((df['ip.dst'] == ip) |\n",
    "                   (df['ip.src'] == ip))]\n",
    "\n",
    "    def filterByCache(self, ip, cache_data, run_filter=True, args=None):\n",
    "        df = self.as_df()\n",
    "        if run_filter:\n",
    "            df = self.run_filter(args)\n",
    "\n",
    "        df_times = df.index.values.tolist()\n",
    "        df_times = [pd.to_datetime(t) for t in df_times]\n",
    "\n",
    "        input_times = cache_data.index.values.tolist()\n",
    "        input_times = [pd.to_datetime(t) for t in input_times]\n",
    "\n",
    "        keepers = [False] * len(df_times)\n",
    "        idx = 0\n",
    "        stop = len(input_times)\n",
    "        for i in range(0, len(df_times)):\n",
    "            if idx >= stop:\n",
    "                break\n",
    "            diff = input_times[idx] - df_times[i]\n",
    "            if diff <= pd.Timedelta(0):\n",
    "                idx += 1\n",
    "            elif diff < self.cache_timing:\n",
    "                keepers[i] = True\n",
    "\n",
    "        return df[keepers]\n",
    "\n",
    "    def search(self, ip=None, cache_data=None):\n",
    "        matches = []\n",
    "        if self.ip_search_enabled and ip is not None:\n",
    "            matches += [self.filterByIP(ip)]\n",
    "        if self.cache_search_enabled and cache_data is not None:\n",
    "            matches += [self.filterByCache(ip, cache_data)]\n",
    "        return matches\n",
    "\n",
    "    def remove_zero_var(self, cutoff=0.01):\n",
    "        df = self.as_df()\n",
    "\n",
    "        numeric_cols = df.select_dtypes(include=np.number)\n",
    "        cols_to_drop = numeric_cols.columns[(numeric_cols.std() <= cutoff) |\n",
    "                                            (numeric_cols.std().isna())]\\\n",
    "                                                    .tolist()\n",
    "        df_filtered = df.drop(cols_to_drop, axis=1)\n",
    "        self.df = df_filtered\n",
    "\n",
    "    def remove_features(self, bad_features):\n",
    "        df = self.as_df()\n",
    "        df.drop(bad_features, inplace=True, axis=1)\n",
    "        self.df = df\n",
    "\n",
    "    def adjust_time_scale(self, offset, scale):\n",
    "        df = self.as_df()\n",
    "        df[self.time_col] = df[self.time_col].apply(lambda x: int(x.timestamp()))\n",
    "        df[self.time_col] = (df[self.time_col] - offset) * scale + offset\n",
    "        col = df[self.time_col]\n",
    "        self.df = df\n",
    "        self.time_format = 'epoch'\n",
    "        self.format_time_col()\n",
    "        self.df = self.df.set_index(self.time_col)\n",
    "        self.df[self.time_col] = col\n",
    "\n",
    "\n",
    "# Basic Scopes\n",
    "\n",
    "# Get all clients and ISP dns scope\n",
    "r = re.compile(r\".*isp.csv|.*group[0-9]*user[0-9]*-(?!127\\.0\\.0\\.1)[0-9]*.[0-9]*.[0-9]*.[0-9]*..csv\")\n",
    "ISP_scope = PrivacyScope(list(filter(r.match, data)), \"ISP\")\n",
    "\n",
    "\n",
    "# Access to public resolver scope\n",
    "r = re.compile(r\".*isp.*.csv\")\n",
    "Access_resolver = PrivacyScope(list(filter(r.match, data)), \"Access_resolver\")\n",
    "\n",
    "r = re.compile(r\"(.*tld).*.csv\")\n",
    "tld = PrivacyScope(list(filter(r.match, data)), \"TLD\")\n",
    "\n",
    "r = re.compile(r\"(.*root).*.csv\")\n",
    "root = PrivacyScope(list(filter(r.match, data)), \"root\")\n",
    "\n",
    "r = re.compile(r\"(.*sld).*.csv\")\n",
    "sld = PrivacyScope(list(filter(r.match, data)), \"SLD\")\n",
    "\n",
    "# Access Tor Scope\n",
    "r = re.compile(r\".*group[0-9]*user[0-9]*-(?!127\\.0\\.0\\.1)[0-9]*.[0-9]*.[0-9]*.[0-9]*..csv\")\n",
    "Access_tor = PrivacyScope(list(filter(r.match, data)), \"Access_tor\")\n",
    "\n",
    "# Server Public Scope\n",
    "r = re.compile(r\".*myMarkovServer0*-(?!127\\.0\\.0\\.1)[0-9]*\\.[0-9]*\\.[0-9]*\\.[0-9]*.csv\")\n",
    "Server_scope = PrivacyScope(list(filter(r.match, data)), \"Server_of_interest\")\n",
    "\n",
    "# tor Exit scope\n",
    "r = re.compile(r\".*exit.*\")\n",
    "Tor_exit_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_exit\")\n",
    "\n",
    "# tor Guard scope\n",
    "r = re.compile(r\".*guard.*\")\n",
    "Tor_guard_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_guard\")\n",
    "\n",
    "# tor Relay scope\n",
    "r = re.compile(r\".*relay.*\")\n",
    "Tor_relay_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_relay\")\n",
    "\n",
    "# tor Middle scope\n",
    "r = re.compile(r\".*middle.*\")\n",
    "Tor_middle_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_middle\")\n",
    "\n",
    "# tor 4uthority scope\n",
    "r = re.compile(r\".*4uthority.*\")\n",
    "Tor_4uthority_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_4uthority\")\n",
    "\n",
    "# resolver scope\n",
    "r = re.compile(r\".*resolver.*\")\n",
    "resolver = PrivacyScope(list(filter(r.match, data)), \"resolver\")\n",
    "\n",
    "\n",
    "def df_to_ts(df):\n",
    "    df.loc[:, 'count'] = 1\n",
    "#    tmp = df.index.to_frame()\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        print(df)\n",
    "    tmp = df.resample('1S').sum(numeric_only=True).infer_objects()\n",
    "    tmp = tmp.reset_index()\n",
    "    return tmp\n",
    "\n",
    "\n",
    "print(\"Scopes created\")\n",
    "\n",
    "\n",
    "def get_GNS3_offset():\n",
    "    # Read the YAML file\n",
    "    with open('data/experiment0-0.01/shadow.config.yaml', 'r') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "\n",
    "    # Extract the value\n",
    "    time = data['hosts']['group0user0']['processes'][2]['args'].split()[1]\n",
    "    return int(time)\n",
    "\n",
    "\n",
    "def get_start_time(scopes):\n",
    "    df = pd.concat([scope.as_df() for scope in scopes])\n",
    "    start_time = df.head(1).index.to_numpy()[0]\n",
    "    return pd.to_datetime(start_time)\n",
    "\n",
    "\n",
    "GNS3_scopes = [resolver,\n",
    "               sld,\n",
    "               tld,\n",
    "               root]\n",
    "\n",
    "GNS3_offset = get_GNS3_offset()\n",
    "scale = 10\n",
    "for scope in GNS3_scopes:\n",
    "    scope.pcap_df()\n",
    "    scope.adjust_time_scale(GNS3_offset, scale)\n",
    "GNS3_starttime = get_start_time(GNS3_scopes)\n",
    "\n",
    "# service log scope\n",
    "r = re.compile(\".*mymarkovservice*.*py.*stdout\")\n",
    "chatlog = PrivacyScope(list(filter(r.match, data)), \"chatlogs\")\n",
    "chatlog.time_col = \"time\"\n",
    "chatlog.time_cut_tail = 0\n",
    "chatlog.time_format = 'epoch'\n",
    "# Subtract an extra second for buffer room to ensure chatlog happens after DNS\n",
    "chatlog.set_index(chatlog.time_col)\n",
    "chatlog.set_offset(GNS3_starttime - chatlog.start_time() - pd.Timedelta(seconds=1))\n",
    "\n",
    "\n",
    "window = pd.Timedelta(\"300 seconds\")  # cache size but maybe smaller\n",
    "\n",
    "assert GNS3_starttime - chatlog.start_time() == pd.Timedelta(seconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15729ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blah\n"
     ]
    }
   ],
   "source": [
    "print(\"blah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f0dd47-957e-4586-98a3-37dee5d43426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPs that must trigger a cache miss: []\n",
      "scopes: [resolver, root, TLD, SLD]\n",
      "cache window: 0 days 00:05:00\n",
      "                                   format                        username   \n",
      "time                                                                        \n",
      "2023-06-14 03:57:20.000  application/json  /tordata/config/group_0_user_2  \\\n",
      "2023-06-14 03:57:30.101  application/json  /tordata/config/group_0_user_2   \n",
      "2023-06-14 03:57:30.301  application/json  /tordata/config/group_0_user_2   \n",
      "2023-06-14 03:57:40.000  application/json  /tordata/config/group_0_user_3   \n",
      "2023-06-14 03:57:40.000  application/json  /tordata/config/group_0_user_4   \n",
      "...                                   ...                             ...   \n",
      "2023-06-14 05:37:50.200  application/json  /tordata/config/group_1_user_1   \n",
      "2023-06-14 05:37:50.400  application/json  /tordata/config/group_1_user_1   \n",
      "2023-06-14 05:37:50.600  application/json  /tordata/config/group_1_user_1   \n",
      "2023-06-14 05:37:50.800  application/json  /tordata/config/group_1_user_1   \n",
      "2023-06-14 05:38:00.000  application/json  /tordata/config/group_1_user_1   \n",
      "\n",
      "                                                                      text  \n",
      "time                                                                        \n",
      "2023-06-14 03:57:20.000  It's this line that tells me everything I need...  \n",
      "2023-06-14 03:57:30.101  While I disagree with the weapon complaint, I ...  \n",
      "2023-06-14 03:57:30.301  Yep. Weapons breaking isn't a big deal at all....  \n",
      "2023-06-14 03:57:40.000  Thank you for taking a balanced point of view....  \n",
      "2023-06-14 03:57:40.000  Judging by his Horizon score, I'm guessing he ...  \n",
      "...                                                                    ...  \n",
      "2023-06-14 05:37:50.200  They are the resistance from TP, an organisati...  \n",
      "2023-06-14 05:37:50.400  [Done.](https://i.imgur.com/lizacrc.jpg) I pos...  \n",
      "2023-06-14 05:37:50.600  I think those are the actual goddesses in this...  \n",
      "2023-06-14 05:37:50.800  Ralph is the fucking best. A lot of the reason...  \n",
      "2023-06-14 05:38:00.000  Yeah, in retrospect, some of them are kind of ...  \n",
      "\n",
      "[4193 rows x 3 columns]\n",
      "hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n",
      "/tmp/ipykernel_3702850/786207633.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, 'count'] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 40 cpus for 35 subsets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                             | 0/35 [00:00<?, ?it/s]Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-39:\n",
      "Process ForkPoolWorker-19:\n",
      "  0%|                                                                                                                                             | 0/35 [00:20<?, ?it/s]Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-34:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-17:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-35:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-40:\n",
      "Process ForkPoolWorker-27:\n",
      "Process ForkPoolWorker-28:\n",
      "Process ForkPoolWorker-37:\n",
      "Process ForkPoolWorker-36:\n",
      "Process ForkPoolWorker-38:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-33:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 366, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/connection.py\", line 426, in _recv_bytes\n",
      "    return self._recv(size)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.9/multiprocessing/connection.py\", line 391, in _recv\n",
      "    buf.write(chunk)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-31:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# detect and remove solo quries\n",
    "# these can easily be handled on their own\n",
    "# as only 1 device is accessing the network at that moment\n",
    "def detect_solo(df_list):\n",
    "    new_df = df_list[df_list['ip.src'].ne(df_list['ip.src'].shift())]\n",
    "    new_df['index_col'] = new_df.index\n",
    "    new_df['diff'] = new_df['index_col'].diff()\n",
    "    new_df = new_df[new_df['diff'] > window]\n",
    "    solo_ips = new_df['ip.src'].unique()\n",
    "    return solo_ips\n",
    "\n",
    "\n",
    "def handle_solo(solo):\n",
    "    print(\"IPs that must trigger a cache miss: \" + str(solo))\n",
    "\n",
    "\n",
    "def solo_pipeline(df_list):\n",
    "    fil = df_list.loc[:, ['ip.src']]\n",
    "    solo = detect_solo(fil)\n",
    "    handle_solo(solo)\n",
    "    return solo\n",
    "\n",
    "\n",
    "def combineScopes(dfs):\n",
    "    if len(dfs) < 1:\n",
    "        return dfs\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "\n",
    "def scopesToTS(dfs):\n",
    "    output = []\n",
    "    for df in dfs:\n",
    "        if len(df) < 2:\n",
    "            continue\n",
    "        output += scopeToTS(df)\n",
    "    return output\n",
    "\n",
    "\n",
    "def scopeToTS(df, time_col):\n",
    "    return df_to_ts(df.copy(deep=True)).set_index(time_col)\n",
    "\n",
    "\n",
    "def scope_label(df, scope_name):\n",
    "    for col in df.columns:\n",
    "        df[col + \"_\" + scope_name] = df[col]\n",
    "    df[\"scope_name\"] = scope_name\n",
    "    return df\n",
    "\n",
    "\n",
    "# Setup filters for different scopes\n",
    "evil_domain = 'evil.dne'\n",
    "DNS_PORT = 17.0\n",
    "DOT_PORT = 853\n",
    "\n",
    "\n",
    "def dns_filter(df, ip):\n",
    "    if ('dns.qry.name' in df.columns and 'tcp.dstport' in df.columns):\n",
    "        return df[(df['dns.qry.name'] == evil_domain)\n",
    "                  | (df['dns.qry.name'].isna())\n",
    "                  & (df['tcp.dstport'] == DOT_PORT)]\n",
    "    else:\n",
    "        return df[(df['dns.qry.name'] == evil_domain)\n",
    "                  | (df['dns.qry.name'].isna())]\n",
    "\n",
    "\n",
    "resolver.set_filter(dns_filter)\n",
    "root.set_filter(dns_filter)\n",
    "tld.set_filter(dns_filter)\n",
    "sld.set_filter(dns_filter)\n",
    "\n",
    "resolver.ip_search_enabled = True\n",
    "resolver.cache_search_enabled = False\n",
    "\n",
    "root.ip_search_enabled = True\n",
    "root.cache_search_enabled = True\n",
    "\n",
    "sld.ip_search_enabled = True\n",
    "sld.cache_search_enabled = True\n",
    "\n",
    "tld.ip_search_enabled = True\n",
    "tld.cache_search_enabled = True\n",
    "\n",
    "TCP_PROTO = 6\n",
    "\n",
    "\n",
    "# def tor_filter(df, ip):\n",
    "#     return df[(df['tcp.len'] > 500) & (df['ip.proto'] == TCP_PROTO)]\n",
    "\n",
    "\n",
    "# Access_tor.set_filter(tor_filter)\n",
    "\n",
    "# Access_tor.ip_search_enabled = True\n",
    "# Access_tor.cache_search_enabled = True\n",
    "\n",
    "\n",
    "# Cluster DNS\n",
    "# Create ts for each IP\n",
    "resolv_df = resolver.as_df()\n",
    "resolv_df_filtered = resolv_df[resolv_df['tcp.dstport'] == DOT_PORT]\n",
    "infra_ip = ['172.20.0.11', '172.20.0.12', '192.168.150.10', '172.20.0.10']\n",
    "ips_seen = resolv_df_filtered['ip.src'].unique()\n",
    "IPs = list(set(ips_seen) - set(infra_ip))\n",
    "flows_ip = {}\n",
    "flows_ts_ip_scoped = {}\n",
    "flows_ts_ip_total = {}\n",
    "first_pass = resolv_df_filtered[((~resolv_df_filtered['ip.src'].isin(infra_ip)))\n",
    "                                & (resolv_df_filtered['dns.qry.name'] == evil_domain)]\n",
    "solo = solo_pipeline(first_pass)\n",
    "\n",
    "# Add all scope data to IPs found in resolver address space\n",
    "# This should be a valid topo sorted list\n",
    "# of the scopes (it will be proccessed in order)\n",
    "scopes = [resolver, root, tld, sld]  # , Access_tor]\n",
    "bad_features = ['tcp.dstport', 'tcp.srcport', 'udp.port', 'tcp.seq']\n",
    "for scope in scopes:\n",
    "    scope.remove_features(bad_features)\n",
    "    scope.remove_zero_var()\n",
    "cache_window = window  # see above\n",
    "print(\"scopes: \" + str(scopes))\n",
    "print(\"cache window: \" + str(cache_window))\n",
    "\n",
    "for ip in IPs:\n",
    "    # Don't add known infra IPs or users that can are solo communicaters\n",
    "    if ip in infra_ip or ip in solo:\n",
    "        continue\n",
    "    flows_ip[ip] = pd.DataFrame()\n",
    "    flows_ts_ip_scoped[ip] = pd.DataFrame()\n",
    "    flows_ts_ip_total[ip] = pd.DataFrame()\n",
    "    for scope in scopes:\n",
    "        # Find matches\n",
    "        matches = scope.search(ip, flows_ip[ip])\n",
    "\n",
    "        # Update df for ip\n",
    "        combined_scope = combineScopes(matches)\n",
    "        combined_scope = scope_label(combined_scope, scope.name)\n",
    "        combined_scope[\"scope_name\"] = scope.name\n",
    "        flows_ip[ip] = combineScopes([flows_ip[ip], combined_scope])\n",
    "\n",
    "        # update ts for ip\n",
    "        new_ts_matches = scopeToTS(combined_scope, scope.time_col)\n",
    "        if len(new_ts_matches) == 0:\n",
    "            continue\n",
    "        new_ts_matches[\"scope_name\"] = scope.name\n",
    "        flows_ts_ip_scoped[ip] = combineScopes([flows_ts_ip_scoped[ip],\n",
    "                                                new_ts_matches])\n",
    "    if len(flows_ip[ip]) > 0:\n",
    "        flows_ts_ip_total[ip] = scopeToTS(flows_ip[ip], scope.time_col)\n",
    "\n",
    "        # order df by time\n",
    "        # flows_ip[ip] = flows_ip[ip].set_index('frame.time')\n",
    "\n",
    "        # sort combined df by timestamp\n",
    "        flows_ip[ip].sort_index(inplace=True)\n",
    "        flows_ts_ip_scoped[ip].sort_index(inplace=True)\n",
    "        flows_ts_ip_total[ip].sort_index(inplace=True)\n",
    "\n",
    "        # Preserve time col to be used for automated feautre engineering\n",
    "        flows_ip[ip]['frame.time'] = flows_ip[ip].index\n",
    "        flows_ts_ip_total[ip]['frame.time'] = flows_ts_ip_total[ip].index\n",
    "\n",
    "        # remove nans with 0\n",
    "        flows_ip[ip].fillna(0, inplace=True)\n",
    "        flows_ts_ip_scoped[ip].fillna(0, inplace=True)\n",
    "        flows_ts_ip_total[ip].fillna(0, inplace=True)\n",
    "\n",
    "        # label scope col as category\n",
    "        flows_ip[ip][\"scope_name\"] = flows_ip[ip][\"scope_name\"].astype('category')\n",
    "        flows_ts_ip_scoped[ip][\"scope_name\"] = flows_ts_ip_scoped[ip][\"scope_name\"].astype('category')\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "# Viz\n",
    "# importing Libraries\n",
    "plt.style.use('default')\n",
    "# code\n",
    "# Visualizing The Open Price of all the stocks\n",
    "# to set the plot size\n",
    "plt.figure(figsize=(16, 8), dpi=150)\n",
    "# using plot method to plot open prices.\n",
    "# in plot method we set the label and color of the curve.\n",
    "\n",
    "total = 0\n",
    "for f in flows_ts_ip_total:\n",
    "    if total > 10:\n",
    "        break\n",
    "    total += 1\n",
    "    flows_ts_ip_total[f]['count'].plot(label=f)\n",
    "\n",
    "plt.title('Requests per second')\n",
    "\n",
    "# adding Label to the x-axis\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Requests (seconds)')\n",
    "\n",
    "# adding legend to the curve\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "def ip_to_group(ip):\n",
    "    if ip.split(\".\")[0] != '101':\n",
    "        return -1\n",
    "    return math.floor((int(ip.split(\".\")[-1])-2) / 5)\n",
    "\n",
    "\n",
    "def get_real_label(dic):\n",
    "    data = dic.keys()\n",
    "    result = np.array([ip_to_group(xi) for xi in data])\n",
    "    return result\n",
    "\n",
    "\n",
    "# compute cluster purity\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)\n",
    "\n",
    "\n",
    "def weighted_purity(true_labels, found_labels):\n",
    "    s = 0\n",
    "    total = 0\n",
    "    for c in true_labels.unique():\n",
    "        selection = df[df['cluster'] == c]\n",
    "        p = purity_score(selection['real_label'], selection['cluster'])\n",
    "        total += len(selection)\n",
    "        s += p * len(selection)\n",
    "    return s/total\n",
    "\n",
    "\n",
    "answers = get_real_label(flows_ts_ip_total)\n",
    "\n",
    "\n",
    "def gpt_cluster_metrics(true_labels, found_labels):\n",
    "    # Calculate the Adjusted Rand Index\n",
    "    ari = adjusted_rand_score(true_labels, found_labels)\n",
    "    ari_range = (-1, 1)\n",
    "    ari_ideal = 1\n",
    "\n",
    "    # Calculate the Normalized Mutual Information\n",
    "    nmi = normalized_mutual_info_score(true_labels, found_labels)\n",
    "    nmi_range = (0, 1)\n",
    "    nmi_ideal = 1\n",
    "\n",
    "    # Calculate the Fowlkes-Mallows Index\n",
    "    fmi = fowlkes_mallows_score(true_labels, found_labels)\n",
    "    fmi_range = (0, 1)\n",
    "    fmi_ideal = 1\n",
    "\n",
    "    # Calculate homogeneity, completeness, and V-measure\n",
    "    homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(true_labels, found_labels)\n",
    "    hcv_range = (0, 1)\n",
    "    hcv_ideal = 1\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Adjusted Rand Index: {ari:.4f} [range: {ari_range}, ideal: {ari_ideal}]\")\n",
    "    print(f\"Normalized Mutual Information: {nmi:.4f} [range: {nmi_range}, ideal: {nmi_ideal}]\")\n",
    "    print(f\"Fowlkes-Mallows Index: {fmi:.4f} [range: {fmi_range}, ideal: {fmi_ideal}]\")\n",
    "    print(f\"Homogeneity: {homogeneity:.4f} [range: {hcv_range}, ideal: {hcv_ideal}]\")\n",
    "    print(f\"Completeness: {completeness:.4f} [range: {hcv_range}, ideal: {hcv_ideal}]\")\n",
    "    print(f\"V-measure: {v_measure:.4f} [range: {hcv_range}, ideal: {hcv_ideal}]\")\n",
    "\n",
    "\n",
    "def my_dtw(ts1, ts2):\n",
    "    distance, path = fastdtw(ts1, ts2)\n",
    "    return distance\n",
    "\n",
    "\n",
    "def my_dist(ts1, ts2, ip1=\"\", ip2=\"\"):\n",
    "    return my_pl_ts(ts1, ts2, ip1, ip2)\n",
    "\n",
    "\n",
    "def rip_ts(window, dim, skip, data, thresh=float(\"inf\")):\n",
    "    for_pl = {}\n",
    "    for i in range(0, len(data)-window+1, skip):\n",
    "        diagrams = ripser(data[i:i+window], maxdim=dim, thresh=thresh)['dgms']\n",
    "        for_pl[i] = diagrams[dim]\n",
    "    return for_pl\n",
    "\n",
    "\n",
    "def tda_trans(pairs, k=2, debug=False):\n",
    "    pairs = [(x[0], x[1]) for x in pairs]\n",
    "    return fast_pl_py.pairs_to_l2_norm(pairs, k, debug)\n",
    "\n",
    "\n",
    "class TDA_Parameters:\n",
    "    def __init__(self, dim, window, skip, k, thresh):\n",
    "        self.dim = dim\n",
    "        self.window = window\n",
    "        self.skip = skip\n",
    "        self.k = k\n",
    "        self.thresh = thresh\n",
    "\n",
    "\n",
    "def ts_to_tda(data, header=\"\", params=TDA_Parameters(0, 3, 1, 2, float(\"inf\")), debug=False):\n",
    "    data = data.astype(float)\n",
    "\n",
    "    # compute birth death pairs\n",
    "    rip_data = rip_ts(params.window, params.dim, params.skip, data, thresh=params.thresh)\n",
    "    new_ts = [tda_trans(pairs, params.k, debug) for i, pairs in rip_data.items()]\n",
    "    return pd.DataFrame({'tda_pl': new_ts}, index=data.index[:len(new_ts)])\n",
    "\n",
    "\n",
    "def my_pl_ts(ts1, ts2, ip1, ip2):\n",
    "    return my_dtw(ts1, ts2)\n",
    "\n",
    "\n",
    "def calc_dist_matrix(samples, my_dist, multi_to_single=lambda x: x):\n",
    "    # create a list of dataframe values\n",
    "    X = [multi_to_single(df.to_numpy(), ip) for ip, df in samples.items()]\n",
    "    n_samples = len(X)\n",
    "    dist_mat = np.zeros((n_samples, n_samples))\n",
    "    for i in range(n_samples):\n",
    "        for j in range(i+1, n_samples):\n",
    "            d = my_dist(X[i], X[j], i, j)\n",
    "            dist_mat[i, j] = d\n",
    "            dist_mat[j, i] = d\n",
    "    return squareform(dist_mat)\n",
    "\n",
    "\n",
    "def cast_col(col: pd.Series) -> pd.Series:\n",
    "    if col.dtype == 'object':\n",
    "        if all([is_float(x) for x in col]):\n",
    "            return col.astype(float)\n",
    "        elif all([is_int(x) for x in col]):\n",
    "            return col.astype(float)\n",
    "        elif all([is_date(x) for x in col]):\n",
    "            return pd.Series(pd.to_datetime(col)).astype(float)\n",
    "        else:\n",
    "            return col.astype(str)\n",
    "    elif np.issubdtype(col.dtype, np.datetime64):\n",
    "        return col.astype(np.int64)\n",
    "    else:\n",
    "        return col.astype(float)\n",
    "\n",
    "\n",
    "def is_float(s: str) -> bool:\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_int(s: str) -> bool:\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_date(s: str) -> bool:\n",
    "    try:\n",
    "        pd.to_datetime(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def cast_columns(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = cast_col(df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_chat_logs(scope):\n",
    "    df = scope.as_df()\n",
    "    print(df)\n",
    "    print(\"hi\")\n",
    "    exit(1)\n",
    "    df[\"text_len\"] = df[\"text\"].apply(len)\n",
    "    users = df[\"username\"].unique()\n",
    "    client_log = {}\n",
    "    for user in users:\n",
    "        client_log[user] = df_to_ts(df[df[\"username\"] == user]).set_index('time')\n",
    "    return client_log\n",
    "\n",
    "\n",
    "client_chat_logs = get_chat_logs(chatlog)\n",
    "\n",
    "\n",
    "def ip_to_user(ip, group_size=5, starting=10):\n",
    "    local_net = int(ip.split(\".\")[-1]) - starting\n",
    "    user = local_net % group_size\n",
    "    group = math.floor(local_net/group_size)\n",
    "    return '/tordata/config/group_' + str(group) + \"_user_\" + str(user)\n",
    "\n",
    "\n",
    "# https://www.datainsightonline.com/post/cross-correlation-with-two-time-series-in-python\n",
    "# from scipy import signal\n",
    "\n",
    "def ccf_values(series1, series2):\n",
    "    p = series1\n",
    "    q = series2\n",
    "    p = (p - np.mean(p)) / (np.std(p) * len(p))\n",
    "    q = (q - np.mean(q)) / (np.std(q))\n",
    "    c = np.correlate(p, q, 'full')\n",
    "    return c\n",
    "\n",
    "\n",
    "def ccf_plot(lags, ccf):\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    ax.plot(lags, ccf)\n",
    "    ax.axhline(-2/np.sqrt(23), color='red', label='5% \\\n",
    "    confidence interval')\n",
    "    ax.axhline(2/np.sqrt(23), color='red')\n",
    "    ax.axvline(x=0, color='black', lw=1)\n",
    "    ax.axhline(y=0, color='black', lw=1)\n",
    "    ax.axhline(y=np.max(ccf), color='blue', lw=1,\n",
    "               linestyle='--', label='highest +/- correlation')\n",
    "    ax.axhline(y=np.min(ccf), color='blue', lw=1,\n",
    "               linestyle='--')\n",
    "    ax.set(ylim=[-1, 1])\n",
    "    ax.set_title('Cross Correlation', weight='bold', fontsize=15)\n",
    "    ax.set_ylabel('Correlation Coefficients', weight='bold',\n",
    "                  fontsize=12)\n",
    "    ax.set_xlabel('Time Lags', weight='bold', fontsize=12)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "def ccf_calc(sig1, sig2):\n",
    "    corr = sm.tsa.stattools.ccf(sig2, sig1, adjusted=False)\n",
    "\n",
    "    # Remove padding and reverse the order\n",
    "    return corr[0:(len(sig2)+1)][::-1]\n",
    "\n",
    "\n",
    "def cross_cor(ts1, ts2, debug=False, max_offset=300, only_positive=True):\n",
    "    # ensure format is correct (only keep first col\n",
    "    # ts1_values = ts1['count'] # ts1.iloc[:,0]\n",
    "    # ts2_values = ts2['count'] # ts2.iloc[:,0]\n",
    "\n",
    "    # Calculate values\n",
    "    # print(ts1)\n",
    "    ccf = ccf_calc(ts1, ts2)\n",
    "    # lags = signal.correlation_lags(len(ts1_values), len(ts2_values))\n",
    "\n",
    "    # keep only positive lag values\n",
    "    # Not needed with stats packate\n",
    "    # if only_positive:\n",
    "    #     ccf = ccf[lags >= 0]\n",
    "    #     lags = lags[lags >= 0]\n",
    "\n",
    "    # ccf = ccf[:min(len(ccf), max_offset)]\n",
    "\n",
    "    # find best\n",
    "    best_cor = max(ccf)\n",
    "    best_lag = np.argmax(ccf)\n",
    "\n",
    "    if debug:\n",
    "        print('best cross correlation: ' + str(best_cor) + \" at time lag: \" + str(best_lag))\n",
    "        print(len(ccf))\n",
    "        print(ccf)\n",
    "        ccf_plot(range(len(ccf)), ccf)\n",
    "    # print(ccf)\n",
    "    # assert best_cor >= -1 and best_cor <= 1\n",
    "    return best_cor, best_lag\n",
    "\n",
    "\n",
    "def compare_ts(ts1, ts2, debug=False):\n",
    "    # dtw_classic, path_classic = dtw(ts1, ts2, dist='square',\n",
    "    #                             method='classic', return_path=True)\n",
    "    # return dtw_classic\n",
    "    # print(ts1)\n",
    "    # print(ts2)\n",
    "    # dist, lag = cross_cor(pd.Series(ts1), pd.Series(ts2))\n",
    "    dist, lag = cross_cor(ts1, ts2, debug=debug)\n",
    "    # assert dist >= -1 and dist <= 1\n",
    "    dist = dist * -1  # flip for use as distance metric\n",
    "    # assert dist >= -1 and dist <= 1\n",
    "    return dist, lag\n",
    "\n",
    "\n",
    "def normalize_ts(ts):\n",
    "    ts = (ts-ts.min())/(ts.max()-ts.min())\n",
    "    return ts.fillna(0)\n",
    "\n",
    "\n",
    "def compare_ts_reshape(ts1, ts2, debug=False):\n",
    "    # buffer_room = 120  # in seconds\n",
    "    range = min(ts2.index.values), max(ts2.index.values)\n",
    "    ts1 = ts1.loc[(ts1.index >= range[0]) & (ts1.index <= range[1])]\n",
    "    # ts1 = ts1[(ts1['frame.time'] >= int(range[0])) &\n",
    "    #           (ts1['frame.time'] <= int(range[1]))]\n",
    "    ts1 = ts1.loc[:, 'tda_pl']\n",
    "\n",
    "    ts1_norm = np.array(ts1.copy())\n",
    "    ts2_norm = np.array(ts2.copy())\n",
    "\n",
    "    # delay = 0\n",
    "\n",
    "    # ts1_norm.index = ts1_norm.index + pd.DateOffset(seconds=delay)\n",
    "\n",
    "    # lock to same range with buffer room\n",
    "    # on each side to account for network (or PPT) delay\n",
    "\n",
    "    # detect if no overlap\n",
    "    if len(ts1_norm) < 2 or len(ts2_norm) < 2:\n",
    "        return float(\"inf\"), 0\n",
    "\n",
    "    # Normalize peaks?\n",
    "    # ts1_norm = normalize_ts(ts1_norm)\n",
    "    # ts2_norm = normalize_ts(ts2_norm)\n",
    "\n",
    "    # plot_ts(ts1_norm, ts2_norm)\n",
    "    # exit(1)\n",
    "\n",
    "    # else:\n",
    "    #     ts1_norm = ts1_norm.tolist()\n",
    "    #     ts2_norm = ts2_norm.tolist()\n",
    "\n",
    "    score, lag = compare_ts(ts1_norm, ts2_norm, debug=debug)\n",
    "\n",
    "    return score, lag\n",
    "\n",
    "\n",
    "def plot_ts(ts1, ts2):\n",
    "    # to set the plot size\n",
    "    plt.figure(figsize=(16, 8), dpi=150)\n",
    "\n",
    "    # normalize_ts(ts1['count']).plot(label='ts1')\n",
    "    # normalize_ts(ts2['count']).plot(label='ts2')\n",
    "    ts1['count'].plot(label='ts1')\n",
    "    ts2['count'].plot(label='ts2')\n",
    "\n",
    "    plt.title('Requests per second')\n",
    "\n",
    "    # adding Label to the x-axis\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Requests (seconds)')\n",
    "\n",
    "    # adding legend to the curve\n",
    "    plt.legend()\n",
    "plot_ts(client_chat_logs['/tordata/config/group_0_user_0'], flows_ts_ip_total['102.0.0.10'])\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "# from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "\n",
    "# def cluster(samples, max_clust, display=False, multi_to_single=lambda x: x):\n",
    "#     dist_mat = calc_dist_matrix(samples,\n",
    "#                                 my_dist,\n",
    "#                                 multi_to_single=multi_to_single)\n",
    "\n",
    "#     # Perform hierarchical clustering using the computed distances\n",
    "#     Z = linkage(dist_mat, method='single')\n",
    "\n",
    "#     # Plot a dendrogram to visualize the clustering\n",
    "#     if display:\n",
    "#         dendrogram(Z)\n",
    "\n",
    "#     # Extract the cluster assignments using the threshold\n",
    "#     labels = fcluster(Z, max_clust, criterion='maxclust')\n",
    "# #     print(labels)\n",
    "\n",
    "#     return labels\n",
    "\n",
    "\n",
    "def evaluate(src_raw, dst_raw, src_features, dst_feaures, display=False, params=TDA_Parameters(0, 3, 1, 1, 1)):\n",
    "    src = {}\n",
    "    dst = {}\n",
    "    for ip in src_raw:\n",
    "        src[ip] = ts_to_tda(src_raw[ip][src_features].copy(deep=True), params=tda_config)\n",
    "    for user in dst_raw:\n",
    "        dst[user] = ts_to_tda(dst_raw[user][dst_feaures].copy(deep=True), params=tda_config)\n",
    "    correct = 0.0\n",
    "    for user in dst:\n",
    "        best_score = 0\n",
    "        best_ip = 0\n",
    "        for ip in src:\n",
    "            score, _ = compare_ts_reshape(src[ip].copy(deep=True), dst[user].copy(deep=True))\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_ip = ip\n",
    "        if user == ip_to_user(best_ip):\n",
    "            correct += 1\n",
    "    accuracy = correct / len(src)\n",
    "    return accuracy\n",
    "# Find best features\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "\n",
    "\n",
    "def findsubsets(s, n):\n",
    "    return list(itertools.combinations(s, n))\n",
    "\n",
    "\n",
    "def evaluate_subset(src_df, dst_df, src_features, dst_feaures, tda_config=None):\n",
    "    try:\n",
    "        score = evaluate(src_df, dst_df, list(src_features), list(dst_feaures), params=tda_config)\n",
    "    except: \n",
    "        score = -1\n",
    "    return score, src_features\n",
    "\n",
    "\n",
    "def iterate_features(src_df, dst_df, n, dst_features, tda_config, filename):\n",
    "    features = src_df[next(iter(src_df))].columns\n",
    "    subsets = findsubsets(features, n)\n",
    "    results = []\n",
    "    num_cpus = int(os.cpu_count()/2)\n",
    "    print(\"Using \" + str(num_cpus) + \" cpus for \" + str(len(subsets)) + \" subsets\")\n",
    "    with mp.Pool(processes=num_cpus) as pool:\n",
    "        results = []\n",
    "        for subset in subsets:\n",
    "            results.append(pool.apply_async(evaluate_subset, args=(src_df, dst_df, subset, dst_features, tda_config)))\n",
    "        with open(filename, 'a') as f:\n",
    "            for result in tqdm(results, total=len(subsets)):\n",
    "                score, subset = result.get()\n",
    "                out = str(score) + \"\\t\" + str(subset) + \"\\n\"\n",
    "                f.write(out)\n",
    "\n",
    "\n",
    "flows_ts_ip_total_str_int = {}\n",
    "for ip in flows_ts_ip_total:\n",
    "    flows_ts_ip_total_str_int[ip] = cast_columns(flows_ts_ip_total[ip])\n",
    "\n",
    "chat_log = {}\n",
    "for user in client_chat_logs:\n",
    "    chat_log[user] = cast_columns(client_chat_logs[user])\n",
    "\n",
    "src_df = flows_ts_ip_total_str_int\n",
    "dst_df = chat_log\n",
    "\n",
    "dst_df_count = {}\n",
    "for user in dst_df:\n",
    "    dst_df_count[user] = dst_df[user]['count']\n",
    "\n",
    "single_user = '/tordata/config/group_0_user_0'\n",
    "single_ip = '102.0.0.10'\n",
    "dst_single = {single_user: dst_df_count[single_user]}\n",
    "src_single = {single_ip: flows_ts_ip_total[single_ip]}\n",
    "# plot_ts(client_chat_logs['/tordata/config/group_0_user_0'],\n",
    "#                           flows_ts_ip_total['102.0.0.10'])\n",
    "\n",
    "# purity = evaluate(src_single, dst_single, ['count'], display=True)\n",
    "# purity = evaluate(src_df, dst_df_count, ['count'], display=True)\n",
    "# print(\"Accuracy: \" + str(purity*100) + \"%\")\n",
    "\n",
    "\n",
    "def evaluate_tda(src_df, dst_df, tda_params):\n",
    "    try:\n",
    "        dst_arr = {}\n",
    "        for ip in dst_df:\n",
    "            dst_arr[ip] = np.array(\n",
    "                    ts_to_tda(\n",
    "                        dst_df[ip].loc[:, features],\n",
    "                        tda_params))\n",
    "        assert dst_arr[single_user].ndim == 1\n",
    "        result = evaluate(src_df, dst_arr, ['count'], display=True, params=tda_params)\n",
    "    except Exception:\n",
    "        result = -1\n",
    "    return result, tda_params.thresh\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "def eval_model(src_raw, dst_raw, src_features, dst_feaures):\n",
    "    src = {}\n",
    "    dst = {}\n",
    "    for ip in src_raw:\n",
    "        src[ip] = ts_to_tda(src_raw[ip][src_features].copy(deep=True), params=tda_config)\n",
    "    for user in dst_raw:\n",
    "        dst[user] = ts_to_tda(dst_raw[user][dst_feaures].copy(deep=True), params=tda_config)\n",
    "    correct = 0.0\n",
    "    for user in tqdm(dst):\n",
    "        best_score = 0\n",
    "        best_ip = 0\n",
    "        for ip in src:\n",
    "            score, _ = compare_ts_reshape(src[ip].copy(deep=True), dst[user].copy(deep=True))\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_ip = ip\n",
    "        if user == ip_to_user(best_ip):\n",
    "            correct += 1\n",
    "    accuracy = correct / len(src)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "num_cpus = os.cpu_count()/2\n",
    "skip = 1\n",
    "dim = 0\n",
    "window = 3\n",
    "k = 9\n",
    "thresh = float(\"inf\")\n",
    "tda_config = TDA_Parameters(dim, window, skip, k, thresh)\n",
    "\n",
    "src_df = flows_ts_ip_total\n",
    "dst_df = client_chat_logs\n",
    "\n",
    "for output_size in range(1, len(dst_df)+1):\n",
    "    for n in range(1, 4):\n",
    "        for features in findsubsets(dst_df[next(iter(dst_df))].columns, output_size):\n",
    "#             dst_arr = {}\n",
    "#             for ip in dst_df:\n",
    "#                 dst_arr[ip] = ts_to_tda(dst_df[ip].loc[:, features], params=tda_config)\n",
    "#             assert dst_arr[single_user].ndim == 2\n",
    "            best_features = iterate_features(src_df, dst_df, n, features, tda_config,\n",
    "                                             \"chatlog_tda_match_dns_all_\" + str(n) +\n",
    "                                             \"_outputFeatures_\" + str(features) +\n",
    "                                             \"_\" + str(datetime.now()) +\n",
    "                                             \".output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bae1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
