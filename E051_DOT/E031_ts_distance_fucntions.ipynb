{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8b33b96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/taylor/.local/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: matplotlib in /home/taylor/.local/lib/python3.10/site-packages (3.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/taylor/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/taylor/.local/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/taylor/.local/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/taylor/.local/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/taylor/.local/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/taylor/.local/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/taylor/.local/lib/python3.10/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/taylor/.local/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas matplotlib\n",
    "# Knapsack NP complete could work\n",
    "# or check for candidate DNSers that would be apart of the resource access and with enough resource access and DNS \n",
    "# could probably determine\\\n",
    "\n",
    "\n",
    "# What if determine candicate from DNSers like above but then look at their input to tor (frame size and timing \n",
    "# input and output with TDA to filter down candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "484c4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give shadow files old names\n",
    "\n",
    "# import shutil\n",
    "# import os\n",
    "# import sys\n",
    "# import re\n",
    "\n",
    "# dr = \"data/experiment0-0.0001\"\n",
    "\n",
    "# pattern = re.compile(\"^[0-9]*.[0-9]*.[0-9]*.[0-9]*..pcap\")\n",
    "\n",
    "\n",
    "# for root, dirs, files in os.walk(dr):\n",
    "#     for file in files:\n",
    "#         if pattern.match(file):\n",
    "#             spl = root.split(\"/\")\n",
    "#             newname = spl[-1]\n",
    "#             sup = (\"/\").join(spl[:-1])\n",
    "#             shutil.move(root+\"/\"+file, sup+\"/\"+newname+\"-\"+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5a75a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get argus flows from PCAPs\n",
    "#!../util/process_data_argus.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4b24dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCAP to CSV\n",
    "#!../util/pcap_to_csv.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3feb9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCAPNG to CSV\n",
    "#!../util/pcapng_to_csv.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7d13f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def getFilenames(path):\n",
    "    return [path+f for f in listdir(path) if isfile(join(path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "84070c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get argus data\n",
    "arguspath = \"data/argus/csv/\"\n",
    "argusCSVs = getFilenames(arguspath)\n",
    "\n",
    "# Get pcap data\n",
    "pcappath = \"data/csv/\"\n",
    "pcapCSVs = getFilenames(pcappath)\n",
    "data = argusCSVs + pcapCSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "49e645d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3e82b639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame.number</th>\n",
       "      <th>frame.time</th>\n",
       "      <th>ip.src</th>\n",
       "      <th>ip.dst</th>\n",
       "      <th>ip.proto</th>\n",
       "      <th>frame.len</th>\n",
       "      <th>ip.len</th>\n",
       "      <th>ip.flags.df</th>\n",
       "      <th>ip.flags.mf</th>\n",
       "      <th>ip.fragment</th>\n",
       "      <th>...</th>\n",
       "      <th>dtls.handshake.extensions_alpn_str_len</th>\n",
       "      <th>dtls.handshake.extensions_key_share_client_length</th>\n",
       "      <th>http.request</th>\n",
       "      <th>udp.port</th>\n",
       "      <th>frame.time_relative</th>\n",
       "      <th>frame.time_delta</th>\n",
       "      <th>tcp.time_relative</th>\n",
       "      <th>tcp.time_delta</th>\n",
       "      <th>tcp.payload</th>\n",
       "      <th>dns.qry.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dec 31, 1969 19:04:01.000000000 EST</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>100.0.0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Dec 31, 1969 19:04:01.100000000 EST</td>\n",
       "      <td>100.0.0.2</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dec 31, 1969 19:04:01.100000000 EST</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>100.0.0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>557</td>\n",
       "      <td>557</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1603010200010001fc030303ec1b87d2f888b138adcfc6...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Dec 31, 1969 19:04:01.200000000 EST</td>\n",
       "      <td>100.0.0.2</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>6</td>\n",
       "      <td>1211</td>\n",
       "      <td>1211</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>160303009b0200009703031640c97b387b6f6f78fcf04b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Dec 31, 1969 19:04:01.200000000 EST</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>100.0.0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1403030001011703030045157e4a14d6343917c0c1c820...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12617</th>\n",
       "      <td>12618</td>\n",
       "      <td>Dec 31, 1969 21:59:52.321786000 EST</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>185.82.127.11</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10551.321786</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>10549.321786</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12618</th>\n",
       "      <td>12619</td>\n",
       "      <td>Dec 31, 1969 21:59:55.580064000 EST</td>\n",
       "      <td>51.89.148.30</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>6</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10554.580064</td>\n",
       "      <td>3.258278</td>\n",
       "      <td>737.450936</td>\n",
       "      <td>6.001000</td>\n",
       "      <td>17030302135917d9957699453bfbeaa91bffed8ce9c192...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12619</th>\n",
       "      <td>12620</td>\n",
       "      <td>Dec 31, 1969 21:59:55.581064000 EST</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>51.89.148.30</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10554.581064</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>737.451936</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12620</th>\n",
       "      <td>12621</td>\n",
       "      <td>Dec 31, 1969 21:59:59.470064000 EST</td>\n",
       "      <td>185.82.127.11</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>6</td>\n",
       "      <td>576</td>\n",
       "      <td>576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10558.470064</td>\n",
       "      <td>3.889000</td>\n",
       "      <td>10556.470064</td>\n",
       "      <td>7.148278</td>\n",
       "      <td>170303021337123983c572da509d91a3bf07eb0289591b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12621</th>\n",
       "      <td>12622</td>\n",
       "      <td>Dec 31, 1969 21:59:59.470064000 EST</td>\n",
       "      <td>102.0.0.85</td>\n",
       "      <td>185.82.127.11</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10558.470064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10556.470064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12622 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       frame.number                           frame.time         ip.src  \\\n",
       "0                 1  Dec 31, 1969 19:04:01.000000000 EST     102.0.0.85   \n",
       "1                 2  Dec 31, 1969 19:04:01.100000000 EST      100.0.0.2   \n",
       "2                 3  Dec 31, 1969 19:04:01.100000000 EST     102.0.0.85   \n",
       "3                 4  Dec 31, 1969 19:04:01.200000000 EST      100.0.0.2   \n",
       "4                 5  Dec 31, 1969 19:04:01.200000000 EST     102.0.0.85   \n",
       "...             ...                                  ...            ...   \n",
       "12617         12618  Dec 31, 1969 21:59:52.321786000 EST     102.0.0.85   \n",
       "12618         12619  Dec 31, 1969 21:59:55.580064000 EST   51.89.148.30   \n",
       "12619         12620  Dec 31, 1969 21:59:55.581064000 EST     102.0.0.85   \n",
       "12620         12621  Dec 31, 1969 21:59:59.470064000 EST  185.82.127.11   \n",
       "12621         12622  Dec 31, 1969 21:59:59.470064000 EST     102.0.0.85   \n",
       "\n",
       "              ip.dst  ip.proto  frame.len  ip.len  ip.flags.df  ip.flags.mf  \\\n",
       "0          100.0.0.2         6         40      40            1            0   \n",
       "1         102.0.0.85         6         40      40            1            0   \n",
       "2          100.0.0.2         6        557     557            1            0   \n",
       "3         102.0.0.85         6       1211    1211            1            0   \n",
       "4          100.0.0.2         6        120     120            1            0   \n",
       "...              ...       ...        ...     ...          ...          ...   \n",
       "12617  185.82.127.11         6         40      40            1            0   \n",
       "12618     102.0.0.85         6        576     576            1            0   \n",
       "12619   51.89.148.30         6         40      40            1            0   \n",
       "12620     102.0.0.85         6        576     576            1            0   \n",
       "12621  185.82.127.11         6         40      40            1            0   \n",
       "\n",
       "       ip.fragment  ...  dtls.handshake.extensions_alpn_str_len  \\\n",
       "0              NaN  ...                                     NaN   \n",
       "1              NaN  ...                                     NaN   \n",
       "2              NaN  ...                                     NaN   \n",
       "3              NaN  ...                                     NaN   \n",
       "4              NaN  ...                                     NaN   \n",
       "...            ...  ...                                     ...   \n",
       "12617          NaN  ...                                     NaN   \n",
       "12618          NaN  ...                                     NaN   \n",
       "12619          NaN  ...                                     NaN   \n",
       "12620          NaN  ...                                     NaN   \n",
       "12621          NaN  ...                                     NaN   \n",
       "\n",
       "       dtls.handshake.extensions_key_share_client_length  http.request  \\\n",
       "0                                                    NaN           NaN   \n",
       "1                                                    NaN           NaN   \n",
       "2                                                    NaN           NaN   \n",
       "3                                                    NaN           NaN   \n",
       "4                                                    NaN           NaN   \n",
       "...                                                  ...           ...   \n",
       "12617                                                NaN           NaN   \n",
       "12618                                                NaN           NaN   \n",
       "12619                                                NaN           NaN   \n",
       "12620                                                NaN           NaN   \n",
       "12621                                                NaN           NaN   \n",
       "\n",
       "       udp.port  frame.time_relative  frame.time_delta  tcp.time_relative  \\\n",
       "0           NaN             0.000000          0.000000           0.000000   \n",
       "1           NaN             0.100000          0.100000           0.100000   \n",
       "2           NaN             0.100000          0.000000           0.100000   \n",
       "3           NaN             0.200000          0.100000           0.200000   \n",
       "4           NaN             0.200000          0.000000           0.200000   \n",
       "...         ...                  ...               ...                ...   \n",
       "12617       NaN         10551.321786          0.005000       10549.321786   \n",
       "12618       NaN         10554.580064          3.258278         737.450936   \n",
       "12619       NaN         10554.581064          0.001000         737.451936   \n",
       "12620       NaN         10558.470064          3.889000       10556.470064   \n",
       "12621       NaN         10558.470064          0.000000       10556.470064   \n",
       "\n",
       "       tcp.time_delta                                        tcp.payload  \\\n",
       "0            0.000000                                                NaN   \n",
       "1            0.100000                                                NaN   \n",
       "2            0.000000  1603010200010001fc030303ec1b87d2f888b138adcfc6...   \n",
       "3            0.100000  160303009b0200009703031640c97b387b6f6f78fcf04b...   \n",
       "4            0.000000  1403030001011703030045157e4a14d6343917c0c1c820...   \n",
       "...               ...                                                ...   \n",
       "12617        0.005000                                                NaN   \n",
       "12618        6.001000  17030302135917d9957699453bfbeaa91bffed8ce9c192...   \n",
       "12619        0.001000                                                NaN   \n",
       "12620        7.148278  170303021337123983c572da509d91a3bf07eb0289591b...   \n",
       "12621        0.000000                                                NaN   \n",
       "\n",
       "      dns.qry.name  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "...            ...  \n",
       "12617          NaN  \n",
       "12618          NaN  \n",
       "12619          NaN  \n",
       "12620          NaN  \n",
       "12621          NaN  \n",
       "\n",
       "[12622 rows x 59 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv (pcapCSVs[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a3cbe7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d4fb54b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(argusCSVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c5747fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrivacyScope:\n",
    "\n",
    "    def __init__(self, filenames, name):\n",
    "        self.name = name\n",
    "        self.filenames = filenames\n",
    "        self.time_format = '%b %d, %Y %X.%f'\n",
    "        self.time_col = 'frame.time'\n",
    "        self.filter_func = lambda df, args: df\n",
    "        self.df = None\n",
    "        self.ip_search_enabled = False\n",
    "        self.cache_search_enabled = False\n",
    "        self.cache_timing = pd.Timedelta(\"300 seconds\")\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"PrivacyScope(\" + self.name + \")\"\n",
    "\n",
    "    def as_df(self, filenames=None):\n",
    "        if self.df is not None:\n",
    "            return self.df\n",
    "        if filenames == None:\n",
    "            filenames = self.filenames\n",
    "        df = pd.DataFrame()\n",
    "        for f in filenames:\n",
    "            ddf = pd.read_csv (f)\n",
    "            df = pd.concat([df, ddf])\n",
    "        self.df = self.format_time_col(df)\n",
    "        return self.df\n",
    "        \n",
    "    def get_ts(self):\n",
    "        return None\n",
    "    \n",
    "    def format_time_col(self, df):\n",
    "        df[self.time_col] = df[self.time_col].apply(lambda x: datetime.strptime(x[:-7], self.time_format))\n",
    "        df.set_index(self.time_col)\n",
    "        return df\n",
    "\n",
    "    def pcap_only(self):\n",
    "        r = re.compile(\".*data/csv.*\")\n",
    "        return list(filter(r.match, self.filenames))\n",
    "    \n",
    "    def pcap_df(self):\n",
    "        return self.as_df(filenames=self.pcap_only())\n",
    "    \n",
    "    def set_filter(self, filter_func):\n",
    "        self.filter_func = filter_func\n",
    "        \n",
    "    def run_filter(self, args):\n",
    "        return self.filter_func(self.as_df(), args)\n",
    "    \n",
    "    def filterByIP(self, ip, run_filter=True, args=None):\n",
    "        df = self.as_df()\n",
    "        if run_filter:\n",
    "            df = self.run_filter(args)\n",
    "        return df[((df['ip.dst'] == ip) | \\\n",
    "                                   (df['ip.src'] == ip))]\n",
    "\n",
    "    def filterByCache(self, ip, cache_data, run_filter=True, args=None):\n",
    "        df = self.as_df()\n",
    "        if run_filter:\n",
    "            df = self.run_filter(args)\n",
    "\n",
    "        df_times = df[self.time_col].tolist()\n",
    "        input_times = cache_data[self.time_col].tolist()\n",
    "        keepers = [False] * len(df_times)\n",
    "        idx = 0\n",
    "        stop = len(input_times)\n",
    "        for i in range(0, len(df_times)):\n",
    "            if idx >= stop:\n",
    "                break\n",
    "            diff = input_times[idx] - df_times[i]\n",
    "            if diff <= pd.Timedelta(0):\n",
    "                idx += 1\n",
    "            elif diff < self.cache_timing:\n",
    "                keepers[i] = True\n",
    "        \n",
    "        return df[keepers]\n",
    "    \n",
    "    def search(self, ip=None, cache_data=None):\n",
    "        matches = []\n",
    "        if self.ip_search_enabled and ip is not None:\n",
    "            matches += [self.filterByIP(ip)]\n",
    "        if self.cache_search_enabled and cache_data is not None:\n",
    "            matches += [self.filterByCache(ip, cache_data)]\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "96dd33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Scopes\n",
    "import re\n",
    "\n",
    "# Get all clients and ISP dns scope\n",
    "r = re.compile(\".*isp.csv|.*group[0-9]*user[0-9]*-(?!127\\.0\\.0\\.1)[0-9]*.[0-9]*.[0-9]*.[0-9]*..csv\")\n",
    "ISP_scope = PrivacyScope(list(filter(r.match, data)), \"ISP\")\n",
    "\n",
    "\n",
    "# Access to public resolver scope\n",
    "r = re.compile(\".*isp.csv\")\n",
    "Access_resolver = PrivacyScope(list(filter(r.match, data)), \"Access_resolver\")\n",
    "\n",
    "r = re.compile(\"(.*tld).csv\")\n",
    "tld = PrivacyScope(list(filter(r.match, data)), \"TLD\")\n",
    "\n",
    "r = re.compile(\"(.*root).csv\")\n",
    "root = PrivacyScope(list(filter(r.match, data)), \"root\")\n",
    "\n",
    "r = re.compile(\"(.*sld).csv\")\n",
    "sld = PrivacyScope(list(filter(r.match, data)), \"SLD\")\n",
    "\n",
    "# Access Tor Scope\n",
    "r = re.compile(\".*group[0-9]*user[0-9]*-(?!127\\.0\\.0\\.1)[0-9]*.[0-9]*.[0-9]*.[0-9]*..csv\")\n",
    "Access_tor = PrivacyScope(list(filter(r.match, data)), \"Access_tor\")\n",
    "\n",
    "# Server Public Scope\n",
    "r = re.compile(\".*myMarkovServer0*-(?!127\\.0\\.0\\.1)[0-9]*\\.[0-9]*\\.[0-9]*\\.[0-9]*.csv\")\n",
    "Server_scope = PrivacyScope(list(filter(r.match, data)), \"Server_of_interest\")\n",
    "\n",
    "# tor Exit scope\n",
    "r = re.compile(\".*exit.*\")\n",
    "Tor_exit_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_exit\")\n",
    "\n",
    "# tor Guard scope\n",
    "r = re.compile(\".*guard.*\")\n",
    "Tor_guard_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_guard\")\n",
    "\n",
    "# tor Relay scope\n",
    "r = re.compile(\".*relay.*\")\n",
    "Tor_relay_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_relay\")\n",
    "\n",
    "# tor Middle scope\n",
    "r = re.compile(\".*middle.*\")\n",
    "Tor_middle_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_middle\")\n",
    "\n",
    "# tor 4uthority scope\n",
    "r = re.compile(\".*4uthority.*\")\n",
    "Tor_4uthority_Scope = PrivacyScope(list(filter(r.match, data)), \"Tor_4uthority\")\n",
    "\n",
    "# resolver scope\n",
    "r = re.compile(\".*resolver.*\")\n",
    "resolver = PrivacyScope(list(filter(r.match, data)), \"resolver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e568221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def df_to_ts(df):\n",
    "    df['count'] = 1\n",
    "    #  Minute is T\n",
    "    tmp = df.set_index('frame.time').infer_objects()\n",
    "#     print(\"1:\\t\" + str(tmp))\n",
    "    tmp = tmp.resample('3S').sum(numeric_only=True).infer_objects()\n",
    "#     print(\"2:\\t\" + str(tmp))\n",
    "    #tmp = tmp.rolling(10).sum(numeric_only=True)\n",
    "    #print(\"3:\\t\" + str(tmp))\n",
    "    return tmp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bdada46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get start time for GNS3\n",
    "GNS3_data = pd.concat([Access_resolver.pcap_df(), sld.pcap_df(), tld.pcap_df(), root.pcap_df()])\n",
    "GNS3_starttime = GNS3_data.head(1)['frame.time'].tolist()[0]\n",
    "Shadow_starttime = datetime.strptime('Dec 31, 1969 19:30:00', '%b %d, %Y %X')\n",
    "Shadow_offset = GNS3_starttime - Shadow_starttime\n",
    "Shadow_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6130e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dns_df = Access_to_auth_zone.pcap_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311216b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = pd.Timedelta(\"300 seconds\") # cache size but maybe smaller \n",
    "\n",
    "# detect and remove solo quries\n",
    "# these can easily be handled on their own as only 1 device is accessing the network at that moment\n",
    "def detect_solo(df_list):\n",
    "    new_df = df_list[df_list['ip.src'].ne(df_list['ip.src'].shift())]\n",
    "    new_df['diff'] = new_df['frame.time'].diff()\n",
    "    new_df = new_df[new_df['diff'] > window]\n",
    "    solo_ips = new_df['ip.src'].unique()\n",
    "    return solo_ips\n",
    "\n",
    "def handle_solo(solo):\n",
    "    print(\"IPs that must trigger a cache miss: \" + str(solo))\n",
    "    \n",
    "def solo_pipeline(df_list):\n",
    "    fil = df_list[['ip.src', 'frame.time']]\n",
    "    solo = detect_solo(fil)\n",
    "    handle_solo(solo)\n",
    "    return solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0afb005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineScopes(dfs):\n",
    "    if len(dfs) < 1:\n",
    "        return dfs\n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def scopesToTS(dfs):\n",
    "    output = []\n",
    "    for df in dfs:\n",
    "        if len(df) < 2:\n",
    "            continue\n",
    "        output += scopeToTS(df)\n",
    "    return output\n",
    "def scopeToTS(df):\n",
    "    return df_to_ts(df.copy()).set_index('frame.time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ce970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scope_label(df, scope_name):\n",
    "    for col in df.columns:\n",
    "        df[col + \"_\" + scope_name] = df[col]\n",
    "    df[\"scope_name\"]=scope_name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587e1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup filters for different scopes\n",
    "evil_domain = 'evil.dne'\n",
    "DNS_PROTO = 17.0\n",
    "\n",
    "dns_filter = lambda df, ip: df[(df['dns.qry.name'] == evil_domain )\n",
    "                                            | (df['dns.qry.name'] == \"\") & (df['ip.proto'] == DNS_PROTO)]\n",
    "resolver.set_filter(dns_filter)\n",
    "root.set_filter(dns_filter)\n",
    "tld.set_filter(dns_filter)\n",
    "sld.set_filter(dns_filter)\n",
    "\n",
    "\n",
    "resolver.ip_search_enabled = True\n",
    "resolver.cache_search_enabled = False\n",
    "\n",
    "root.ip_search_enabled = True\n",
    "root.cache_search_enabled = True\n",
    "\n",
    "sld.ip_search_enabled = True\n",
    "sld.cache_search_enabled = True\n",
    "\n",
    "tld.ip_search_enabled = True\n",
    "tld.cache_search_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ebca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster DNS\n",
    "## Create ts for each IP\n",
    "resolv_df = resolver.pcap_df()\n",
    "resolv_df_filtered = resolv_df[resolv_df['ip.proto'] == DNS_PROTO]\n",
    "IPs = resolv_df_filtered['ip.src'].unique()\n",
    "flows_ip = {}\n",
    "flows_ts_ip_scoped = {}\n",
    "flows_ts_ip_total = {}\n",
    "infra_ip = ['172.20.0.11', '172.20.0.12', '192.168.150.10', '172.20.0.10']\n",
    "first_pass = resolv_df_filtered[((~resolv_df_filtered['ip.src'].isin(infra_ip)))  \\\n",
    "                                         & (resolv_df_filtered['dns.qry.name'] == evil_domain)]\n",
    "solo = solo_pipeline(first_pass)\n",
    "\n",
    "# Add all scope data to IPs found in resolver address space\n",
    "# This should be a valid topo sorted list of the scopes (it will be proccessed in order)\n",
    "scopes = [resolver, root, tld, sld]\n",
    "cache_window = window # see above \n",
    "print(\"scopes: \" + str(scopes))\n",
    "print(\"cache window: \" + str(cache_window))\n",
    "\n",
    "for ip in IPs:\n",
    "    # Don't add known infra IPs or users that can are solo communicaters\n",
    "    if ip in infra_ip or ip in solo:\n",
    "        continue\n",
    "    flows_ip[ip] = pd.DataFrame()\n",
    "    flows_ts_ip_scoped[ip] = pd.DataFrame()\n",
    "    flows_ts_ip_total[ip] = pd.DataFrame()\n",
    "    for scope in scopes:\n",
    "#         print(scope)\n",
    "        # Find matches\n",
    "        matches = scope.search(ip, flows_ip[ip])\n",
    "        \n",
    "        # Update df for ip\n",
    "        combined_scope = combineScopes(matches)\n",
    "        combined_scope = scope_label(combined_scope, scope.name)\n",
    "        combined_scope[\"scope_name\"]=scope.name\n",
    "        flows_ip[ip] =combineScopes([flows_ip[ip],combined_scope])\n",
    "        \n",
    "        # update ts for ip\n",
    "        new_ts_matches = scopeToTS(combined_scope)\n",
    "#         print(combined_scope)\n",
    "#         print(new_ts_matches)\n",
    "        if len(new_ts_matches) == 0:\n",
    "            continue\n",
    "        new_ts_matches[\"scope_name\"]=scope.name\n",
    "        flows_ts_ip_scoped[ip] = combineScopes([flows_ts_ip_scoped[ip], new_ts_matches])\n",
    "    if len(flows_ip[ip]) > 0:\n",
    "        flows_ts_ip_total[ip] = scopeToTS(flows_ip[ip])\n",
    "        \n",
    "        # order df by time\n",
    "        flows_ip[ip] = flows_ip[ip].set_index('frame.time')\n",
    "        \n",
    "        # sort combined df by timestamp\n",
    "        flows_ip[ip].sort_index(inplace=True)\n",
    "        flows_ts_ip_scoped[ip].sort_index(inplace=True)\n",
    "        flows_ts_ip_total[ip].sort_index(inplace=True)\n",
    "        \n",
    "        # Preserve time col to be used for automated feautre engineering\n",
    "        flows_ip[ip]['frame.time'] = flows_ip[ip].index\n",
    "        flows_ts_ip_total[ip]['frame.time'] = flows_ts_ip_total[ip].index\n",
    "        \n",
    "        # label scope col as category\n",
    "        flows_ip[ip][\"scope_name\"] = flows_ip[ip][\"scope_name\"].astype('category')\n",
    "        flows_ts_ip_scoped[ip][\"scope_name\"] = flows_ts_ip_scoped[ip][\"scope_name\"].astype('category')\n",
    "        \n",
    "        # remove nans with 0\n",
    "        flows_ip[ip].fillna(0, inplace=True)\n",
    "        flows_ts_ip_scoped[ip].fillna(0, inplace=True)\n",
    "        flows_ts_ip_total[ip].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a0b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_ip[ip]['dns.qry.name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c62531",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_ip[ip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63966c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_ts_ip_total[ip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract scope order\n",
    "flows_ip[ip][\"scope_name\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e47083",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Viz\n",
    "# importing Libraries\n",
    "  \n",
    "# import pandas as pd\n",
    "import pandas as pd\n",
    "  \n",
    "# importing matplotlib module\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "  \n",
    "# %matplotlib inline: only draw static\n",
    "# images in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6360cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "# Visualizing The Open Price of all the stocks\n",
    "  \n",
    "# to set the plot size\n",
    "plt.figure(figsize=(16, 8), dpi=150)\n",
    "  \n",
    "# using plot method to plot open prices.\n",
    "# in plot method we set the label and color of the curve.\n",
    "\n",
    "for f in flows_ts_ip_total:\n",
    "    flows_ts_ip_total[f]['count'].plot(label=f)\n",
    "  \n",
    "plt.title('Requests per second')\n",
    "  \n",
    "# adding Label to the x-axis\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Requests (seconds)')\n",
    "  \n",
    "# adding legend to the curve\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def ip_to_group(ip):\n",
    "    if ip.split(\".\")[0] != '102':\n",
    "        return -1\n",
    "    return math.floor((int(ip.split(\".\")[-1])-2) / 5)\n",
    "def get_real_label(dic):\n",
    "    data = dic.keys()\n",
    "    result = np.array([ip_to_group(xi) for xi in data])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09924f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = get_real_label(flows_ts_ip_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f314db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from statistics import mean\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# compute cluster purity\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) \n",
    "\n",
    "def weighted_purity(true_labels, found_labels):\n",
    "    s = 0\n",
    "    total = 0\n",
    "    for c in true_labels.unique():\n",
    "        selection = df[df['cluster'] == c]\n",
    "        p = purity_score(selection['real_label'], selection['cluster'])\n",
    "        total += len(selection)\n",
    "        s += p * len(selection)\n",
    "    return s/total\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score, homogeneity_completeness_v_measure\n",
    "def gpt_cluster_metrics(true_labels, found_labels):\n",
    "\n",
    "    # Calculate the Adjusted Rand Index\n",
    "    ari = adjusted_rand_score(true_labels, found_labels)\n",
    "    ari_range = (-1, 1)\n",
    "    ari_ideal = 1\n",
    "\n",
    "    # Calculate the Normalized Mutual Information\n",
    "    nmi = normalized_mutual_info_score(true_labels, found_labels)\n",
    "    nmi_range = (0, 1)\n",
    "    nmi_ideal = 1\n",
    "\n",
    "    # Calculate the Fowlkes-Mallows Index\n",
    "    fmi = fowlkes_mallows_score(true_labels, found_labels)\n",
    "    fmi_range = (0, 1)\n",
    "    fmi_ideal = 1\n",
    "\n",
    "    # Calculate homogeneity, completeness, and V-measure\n",
    "    homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(true_labels, found_labels)\n",
    "    hcv_range = (0, 1)\n",
    "    hcv_ideal = 1\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Adjusted Rand Index: {ari:.4f} [range: {ari_range}, ideal: {ari_ideal}]\")\n",
    "    print(f\"Normalized Mutual Information: {nmi:.4f} [range: {nmi_range}, ideal: {nmi_ideal}]\")\n",
    "    print(f\"Fowlkes-Mallows Index: {fmi:.4f} [range: {fmi_range}, ideal: {fmi_ideal}]\")\n",
    "    print(f\"Homogeneity: {homogeneity:.4f} [range: {hcv_range}, ideal: {hcv_ideal}]\")\n",
    "    print(f\"Completeness: {completeness:.4f} [range: {hcv_range}, ideal: {hcv_ideal}]\")\n",
    "    print(f\"V-measure: {v_measure:.4f} [range: {hcv_range}, ideal: {hcv_ideal}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9662a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fastdtw\n",
    "from fastdtw import fastdtw\n",
    "def my_dist(ts1, ts2):\n",
    "    distance, path = fastdtw(ts1, ts2)\n",
    "    return distance\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "def calc_dist_matrix(samples, my_dist):\n",
    "    # create a list of dataframe values\n",
    "#     print(samples)\n",
    "    X = [df.values.flatten() for df in samples.values()]\n",
    "    n_samples = len(X)\n",
    "    dist_mat = np.zeros((n_samples, n_samples))\n",
    "    for i in range(n_samples):\n",
    "        for j in range(i+1, n_samples):\n",
    "            d = my_dist(X[i], X[j])\n",
    "            dist_mat[i, j] = d\n",
    "            dist_mat[j, i] = d\n",
    "    return squareform(dist_mat)\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "def cluster(samples, max_clust, display=False):\n",
    "    dist_mat = calc_dist_matrix(samples, my_dist)\n",
    "    \n",
    "    # Perform hierarchical clustering using the computed distances\n",
    "    Z = linkage(dist_mat, method='single')\n",
    "    \n",
    "    # Plot a dendrogram to visualize the clustering\n",
    "    if display:\n",
    "        dendrogram(Z)\n",
    "\n",
    "    # Extract the cluster assignments using the threshold\n",
    "    labels = fcluster(Z, max_clust, criterion='maxclust')\n",
    "#     print(labels)\n",
    "\n",
    "    return labels\n",
    "\n",
    "def evaluate(df_dict, features, display=False):\n",
    "    data = {key: df.copy(deep=True) for key, df in df_dict.items()}\n",
    "    for ip in data:\n",
    "        data[ip] = data[ip][list(features)]\n",
    "#     print(answers)\n",
    "    max_clust = len(np.unique(answers))\n",
    "    return purity_score(answers, cluster(data, max_clust, display))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33273529",
   "metadata": {},
   "outputs": [],
   "source": [
    "purity = evaluate(flows_ts_ip_total, ['frame.time'], display=True)\n",
    "print(\"Average purity: \" + str(purity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best features \n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    " \n",
    "def findsubsets(s, n):\n",
    "    return list(itertools.combinations(s, n))\n",
    "\n",
    "def evaluate_subset(df, subset):\n",
    "    score = evaluate(df, subset)\n",
    "    return score, subset\n",
    "            \n",
    "def iterate_features(df, n, filename):\n",
    "    features = df[next(iter(df))].columns\n",
    "    subsets = findsubsets(features, n)\n",
    "    with open(filename, 'a') as f, mp.Pool() as pool:\n",
    "        evaluate_subset_partial = partial(evaluate_subset, df)\n",
    "        futures = pool.map_async(evaluate_subset_partial, subsets)\n",
    "        for score, subset in tqdm(futures.get(), total=len(futures)):\n",
    "            f.write(str(score) + \"\\t\" + str(subset) + \"\\n\")\n",
    "\n",
    "for n in range(2,4):\n",
    "    best_features = iterate_features(flows_ts_ip_total, n, \"dtws_dns_all_\"+str(n)+ \"_\"+str(datetime.now()) + \".output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042ccb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
